{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNest_inference.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"13FwnbvL-TpcVLgeLfAv09DNO8bL9hUet","authorship_tag":"ABX9TyPG9pdDaTW077JIIRnUnvCb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"173df37a78b94d3c904185044106384c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f6459ecd807843c180d21f37a95942a2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a0ccd21e07704d048b45a4bbfd755f59","IPY_MODEL_3cc7197d40c54b6e90ea8777e25cbd24"]}},"f6459ecd807843c180d21f37a95942a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a0ccd21e07704d048b45a4bbfd755f59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f739ca0f9a7e4cc294137f56fd40fed0","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":110273258,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":110273258,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c412a943ec9c4e79a8526625c873e083"}},"3cc7197d40c54b6e90ea8777e25cbd24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7646d40ed0fc423099f92a6b6c124e04","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 105M/105M [00:06&lt;00:00, 16.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4375ad4aed06401bbfe134422722d63f"}},"f739ca0f9a7e4cc294137f56fd40fed0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c412a943ec9c4e79a8526625c873e083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7646d40ed0fc423099f92a6b6c124e04":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4375ad4aed06401bbfe134422722d63f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61BLz2h528PJ","executionInfo":{"status":"ok","timestamp":1618202723392,"user_tz":240,"elapsed":954534,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"424a5eb9-318b-46f8-9888-d40b83e77c8b"},"source":["!git clone https://github.com/zhanghang1989/PyTorch-Encoding\n","%cd /content/PyTorch-Encoding/\n","!python setup.py install\n","!pip install git+https://github.com/zhanghang1989/PyTorch-Encoding/\n","!pip install git+https://github.com/facebookresearch/fvcore.git"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'PyTorch-Encoding'...\n","remote: Enumerating objects: 49, done.\u001b[K\n","remote: Counting objects: 100% (49/49), done.\u001b[K\n","remote: Compressing objects: 100% (29/29), done.\u001b[K\n","remote: Total 1801 (delta 19), reused 42 (delta 19), pack-reused 1752\u001b[K\n","Receiving objects: 100% (1801/1801), 21.20 MiB | 38.76 MiB/s, done.\n","Resolving deltas: 100% (986/986), done.\n","/content/PyTorch-Encoding\n","-- Building version 1.2.2b20210412\n","c++:  ['/content/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.cpp', '/content/PyTorch-Encoding/encoding/lib/cpu/operator.cpp', '/content/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.cpp', '/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp', '/content/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp', '/content/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.cpp']\n","cuda:  ['/content/PyTorch-Encoding/encoding/lib/gpu/operator.cpp', '/content/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.cu', '/content/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.cu', '/content/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.cu', '/content/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.cu', '/content/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.cu', '/content/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.cu', '/content/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu']\n","running install\n","running bdist_egg\n","running egg_info\n","creating torch_encoding.egg-info\n","writing torch_encoding.egg-info/PKG-INFO\n","writing dependency_links to torch_encoding.egg-info/dependency_links.txt\n","writing requirements to torch_encoding.egg-info/requires.txt\n","writing top-level names to torch_encoding.egg-info/top_level.txt\n","writing manifest file 'torch_encoding.egg-info/SOURCES.txt'\n","/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:369: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n","  warnings.warn(msg.format('we could not find ninja.'))\n","writing manifest file 'torch_encoding.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/encoding\n","copying encoding/parallel.py -> build/lib.linux-x86_64-3.7/encoding\n","copying encoding/__init__.py -> build/lib.linux-x86_64-3.7/encoding\n","copying encoding/version.py -> build/lib.linux-x86_64-3.7/encoding\n","creating build/lib.linux-x86_64-3.7/encoding/functions\n","copying encoding/functions/customize.py -> build/lib.linux-x86_64-3.7/encoding/functions\n","copying encoding/functions/syncbn.py -> build/lib.linux-x86_64-3.7/encoding/functions\n","copying encoding/functions/__init__.py -> build/lib.linux-x86_64-3.7/encoding/functions\n","copying encoding/functions/dist_syncbn.py -> build/lib.linux-x86_64-3.7/encoding/functions\n","copying encoding/functions/encoding.py -> build/lib.linux-x86_64-3.7/encoding/functions\n","copying encoding/functions/rectify.py -> build/lib.linux-x86_64-3.7/encoding/functions\n","creating build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/cityscapes.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/pascal_aug.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/imagenet.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/pcontext.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/pascal_voc.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/ade20k.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/base.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/hpw18.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/folder.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/__init__.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/minc.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/cityscapescoarse.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","copying encoding/datasets/coco.py -> build/lib.linux-x86_64-3.7/encoding/datasets\n","creating build/lib.linux-x86_64-3.7/encoding/models\n","copying encoding/models/model_store.py -> build/lib.linux-x86_64-3.7/encoding/models\n","copying encoding/models/deepten.py -> build/lib.linux-x86_64-3.7/encoding/models\n","copying encoding/models/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models\n","copying encoding/models/model_zoo.py -> build/lib.linux-x86_64-3.7/encoding/models\n","creating build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/customize.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/syncbn.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/attention.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/__init__.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/loss.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/encoding.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/rectify.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/splat.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","copying encoding/nn/dropblock.py -> build/lib.linux-x86_64-3.7/encoding/nn\n","creating build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/pallete.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/presets.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/files.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/metrics.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/lr_scheduler.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/dist_helper.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/misc.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/__init__.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/train_helper.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","copying encoding/utils/precise_bn.py -> build/lib.linux-x86_64-3.7/encoding/utils\n","creating build/lib.linux-x86_64-3.7/encoding/transforms\n","copying encoding/transforms/transforms.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n","copying encoding/transforms/__init__.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n","copying encoding/transforms/autoaug.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n","copying encoding/transforms/get_transform.py -> build/lib.linux-x86_64-3.7/encoding/transforms\n","creating build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/encnet.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/fcn.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/fcfpn.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/upernet.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/base.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/atten.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/deeplab.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","copying encoding/models/sseg/psp.py -> build/lib.linux-x86_64-3.7/encoding/models/sseg\n","creating build/lib.linux-x86_64-3.7/encoding/models/backbone\n","copying encoding/models/backbone/wideresnet.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n","copying encoding/models/backbone/xception.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n","copying encoding/models/backbone/resnext.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n","copying encoding/models/backbone/resnest.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n","copying encoding/models/backbone/resnet_variants.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n","copying encoding/models/backbone/__init__.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n","copying encoding/models/backbone/resnet.py -> build/lib.linux-x86_64-3.7/encoding/models/backbone\n","creating build/lib.linux-x86_64-3.7/encoding/lib\n","creating build/lib.linux-x86_64-3.7/encoding/lib/cpu\n","copying encoding/lib/cpu/operator.h -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n","copying encoding/lib/cpu/syncbn_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n","copying encoding/lib/cpu/operator.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n","copying encoding/lib/cpu/rectify_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n","copying encoding/lib/cpu/nms_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n","copying encoding/lib/cpu/roi_align_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n","copying encoding/lib/cpu/encoding_cpu.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/cpu\n","creating build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/device_tensor.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/operator.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/common.h -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/operator.cpp -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/rectify_cuda.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/encoding_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/activation_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/roi_align_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/lib_ssd.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/syncbn_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","copying encoding/lib/gpu/nms_kernel.cu -> build/lib.linux-x86_64-3.7/encoding/lib/gpu\n","running build_ext\n","building 'encoding.cpu' extension\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/content\n","creating build/temp.linux-x86_64-3.7/content/PyTorch-Encoding\n","creating build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding\n","creating build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib\n","creating build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.cpp -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for if ((end - begin) >= grain_size)\n"," \n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/cpu/operator.cpp -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/operator.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/torch.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/operator.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/operator.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for if ((end - begin) >= grain_size)\n"," \n","In file included from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/operator.cpp:1:0\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/operator.h:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[Kpybind11::array_t<float> apply_transform(int, int, int, pybind11::array_t<float>, pybind11::array_t<float>)\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/operator.h:96:29:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Knarrowing conversion of â€˜\u001b[01m\u001b[K(long unsigned int)img_buf.pybind11::buffer_info::size\u001b[m\u001b[Kâ€™ from â€˜\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[Kâ€™ to â€˜\u001b[01m\u001b[Kpybind11::ssize_t {aka long int}\u001b[m\u001b[Kâ€™ inside { } [\u001b[01;35m\u001b[K-Wnarrowing\u001b[m\u001b[K]\n","   py::array_t<float> result{\u001b[01;35m\u001b[K(unsigned long)img_buf.size\u001b[m\u001b[K};\n","                             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.cpp -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.cpp:2\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for if ((end - begin) >= grain_size)\n"," \n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for if ((end - begin) >= grain_size)\n"," \n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:61:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for\n"," \n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for\n"," \n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[Kstd::vector<at::Tensor> Non_Max_Suppression_CPU(const at::Tensor&, const at::Tensor&, double)\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[Kâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   AT_ASSERT(input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n","                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:225:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[Kâ€™\n"," #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n","                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:244:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[Kâ€™\n"," #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n","                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:291:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[Kâ€™\n","   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {       \\\n","       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:470:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[Kâ€™\n","     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n","                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[Kâ€™\n","   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(input.type().scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n","   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n","                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[Kâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   AT_ASSERT(input.type().scalarType() == at::kFloat || input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kDouble);\n","                                                                   \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:225:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[Kâ€™\n"," #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n","                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:244:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[Kâ€™\n"," #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n","                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:291:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[Kâ€™\n","   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {       \\\n","       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:470:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[Kâ€™\n","     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n","                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:35:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[Kâ€™\n","   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(input.type().scalarType() == at::kFloat || input.type().scalarType() == at::kDouble);\n","   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n","                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[Kâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   AT_ASSERT(scores.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n","                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:225:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[Kâ€™\n"," #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n","                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:244:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[Kâ€™\n"," #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n","                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:291:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[Kâ€™\n","   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {       \\\n","       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:470:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[Kâ€™\n","     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n","                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[Kâ€™\n","   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n","   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n","                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:5:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:69:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[Kâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   AT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kDouble);\n","                                                                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:225:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin definition of macro â€˜\u001b[01m\u001b[KC10_EXPAND_MSVC_WORKAROUND\u001b[m\u001b[Kâ€™\n"," #define C10_EXPAND_MSVC_WORKAROUND(x) \u001b[01;36m\u001b[Kx\u001b[m\u001b[K\n","                                       \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:244:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KC10_UNLIKELY\u001b[m\u001b[Kâ€™\n"," #define C10_UNLIKELY_OR_CONST(e) \u001b[01;36m\u001b[KC10_UNLIKELY\u001b[m\u001b[K(e)\n","                                  \u001b[01;36m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:291:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[Kâ€™\n","   if (\u001b[01;36m\u001b[KC10_UNLIKELY_OR_CONST\u001b[m\u001b[K(!(cond))) {       \\\n","       \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:470:32:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[Kâ€™\n","     C10_EXPAND_MSVC_WORKAROUND(\u001b[01;36m\u001b[KTORCH_INTERNAL_ASSERT\u001b[m\u001b[K(__VA_ARGS__)); \\\n","                                \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:36:3:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin expansion of macro â€˜\u001b[01m\u001b[KAT_ASSERT\u001b[m\u001b[Kâ€™\n","   \u001b[01;36m\u001b[KA\u001b[m\u001b[KT_ASSERT(scores.type().scalarType() == at::kFloat || scores.type().scalarType() == at::kDouble);\n","   \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n","                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:46:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[Kâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   auto mask = torch::zeros({batch_size, num_boxes}, input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.toScalarType(at::kByte));\n","                                                                \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n","                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:49:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = unsigned char]\u001b[m\u001b[Kâ€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   auto *rawMask = mask.data<unsigned char>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:398:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:50:44:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = long int]\u001b[m\u001b[Kâ€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   auto *rawIdx = sorted_inds.data<int64_t>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:398:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:52:18:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[Kâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   if (input.type(\u001b[01;35m\u001b[K)\u001b[m\u001b[K.scalarType() == at::kFloat)\n","                  \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   DeprecatedTypeProperties & \u001b[01;36m\u001b[Ktype\u001b[m\u001b[K() const {\n","                              \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:54:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = float]\u001b[m\u001b[Kâ€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     auto *rawInput = input.data<float>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:398:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:77:41:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[KT* at::Tensor::data() const [with T = double]\u001b[m\u001b[Kâ€™ is deprecated: Tensor.data<T>() is deprecated. Please use Tensor.data_ptr<T>() instead. [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","     auto *rawInput = input.data<double>(\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n","                                         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:398:7:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n","   T * \u001b[01;36m\u001b[Kdata\u001b[m\u001b[K() const {\n","       \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for if ((end - begin) >= grain_size)\n"," \n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.cpp:183:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for private(c) \\\n"," \n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.cpp -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/syncbn_cpu.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/operator.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/rectify_cpu.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/nms_cpu.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/roi_align_cpu.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/cpu/encoding_cpu.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/encoding/cpu.cpython-37m-x86_64-linux-gnu.so\n","building 'encoding.gpu' extension\n","creating build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -DWITH_CUDA -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/gpu/operator.cpp -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/operator.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n","In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/gpu/operator.h:1\u001b[m\u001b[K,\n","                 from \u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/gpu/operator.cpp:1\u001b[m\u001b[K:\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n"," #pragma omp parallel for if ((end - begin) >= grain_size)\n"," \n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.cu -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.cu -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.cu -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.cu -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.cu -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.cu -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","/usr/local/cuda/bin/nvcc -DWITH_CUDA -I/content/PyTorch-Encoding/encoding/lib/cpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/content/PyTorch-Encoding/encoding/lib/gpu -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c /content/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu -o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=gpu -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=compute_60 -gencode=arch=compute_60,code=sm_60 -std=c++14\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu:\u001b[m\u001b[K In function â€˜\u001b[01m\u001b[Kstd::vector<at::Tensor> Non_Max_Suppression_CUDA(const at::Tensor&, const at::Tensor&, double)\u001b[m\u001b[Kâ€™:\n","\u001b[01m\u001b[K/content/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.cu:80:62:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kâ€˜\u001b[01m\u001b[Kat::DeprecatedTypeProperties& at::Tensor::type() const\u001b[m\u001b[Kâ€™ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [\u001b[01;35m\u001b[K-Wdeprecated-declarations\u001b[m\u001b[K]\n","   auto mask = torch::zeros({batch_size, num_boxes}, input.typ\u001b[01;35m\u001b[Ke\u001b[m\u001b[K().toScalarType(at::kByte));\n","                                                              \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:1:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kdeclared here\n"," \u001b[01;36m\u001b[K  De\u001b[m\u001b[KprecatedTypeProperties & type() const {\n"," \u001b[01;36m\u001b[K^\u001b[m\u001b[K \u001b[01;36m\u001b[K~~\u001b[m\u001b[K\n","x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/operator.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/rectify_cuda.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/encoding_kernel.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/activation_kernel.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/roi_align_kernel.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/lib_ssd.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/syncbn_kernel.o build/temp.linux-x86_64-3.7/content/PyTorch-Encoding/encoding/lib/gpu/nms_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/encoding/gpu.cpython-37m-x86_64-linux-gnu.so\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/encoding\n","creating build/bdist.linux-x86_64/egg/encoding/functions\n","copying build/lib.linux-x86_64-3.7/encoding/functions/customize.py -> build/bdist.linux-x86_64/egg/encoding/functions\n","copying build/lib.linux-x86_64-3.7/encoding/functions/syncbn.py -> build/bdist.linux-x86_64/egg/encoding/functions\n","copying build/lib.linux-x86_64-3.7/encoding/functions/__init__.py -> build/bdist.linux-x86_64/egg/encoding/functions\n","copying build/lib.linux-x86_64-3.7/encoding/functions/dist_syncbn.py -> build/bdist.linux-x86_64/egg/encoding/functions\n","copying build/lib.linux-x86_64-3.7/encoding/functions/encoding.py -> build/bdist.linux-x86_64/egg/encoding/functions\n","copying build/lib.linux-x86_64-3.7/encoding/functions/rectify.py -> build/bdist.linux-x86_64/egg/encoding/functions\n","creating build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/cityscapes.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/pascal_aug.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/imagenet.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/pcontext.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/pascal_voc.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/ade20k.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/base.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/hpw18.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/folder.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/__init__.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/minc.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/cityscapescoarse.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","copying build/lib.linux-x86_64-3.7/encoding/datasets/coco.py -> build/bdist.linux-x86_64/egg/encoding/datasets\n","creating build/bdist.linux-x86_64/egg/encoding/models\n","creating build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/encnet.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/fcn.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/fcfpn.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/upernet.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/base.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/atten.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/deeplab.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/sseg/psp.py -> build/bdist.linux-x86_64/egg/encoding/models/sseg\n","copying build/lib.linux-x86_64-3.7/encoding/models/model_store.py -> build/bdist.linux-x86_64/egg/encoding/models\n","copying build/lib.linux-x86_64-3.7/encoding/models/deepten.py -> build/bdist.linux-x86_64/egg/encoding/models\n","copying build/lib.linux-x86_64-3.7/encoding/models/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models\n","creating build/bdist.linux-x86_64/egg/encoding/models/backbone\n","copying build/lib.linux-x86_64-3.7/encoding/models/backbone/wideresnet.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n","copying build/lib.linux-x86_64-3.7/encoding/models/backbone/xception.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n","copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnext.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n","copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnest.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n","copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnet_variants.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n","copying build/lib.linux-x86_64-3.7/encoding/models/backbone/__init__.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n","copying build/lib.linux-x86_64-3.7/encoding/models/backbone/resnet.py -> build/bdist.linux-x86_64/egg/encoding/models/backbone\n","copying build/lib.linux-x86_64-3.7/encoding/models/model_zoo.py -> build/bdist.linux-x86_64/egg/encoding/models\n","copying build/lib.linux-x86_64-3.7/encoding/cpu.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/encoding\n","creating build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/customize.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/syncbn.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/attention.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/__init__.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/loss.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/encoding.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/rectify.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/splat.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","copying build/lib.linux-x86_64-3.7/encoding/nn/dropblock.py -> build/bdist.linux-x86_64/egg/encoding/nn\n","creating build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/pallete.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/presets.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/files.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/metrics.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/lr_scheduler.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/dist_helper.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/misc.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/__init__.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/train_helper.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","copying build/lib.linux-x86_64-3.7/encoding/utils/precise_bn.py -> build/bdist.linux-x86_64/egg/encoding/utils\n","creating build/bdist.linux-x86_64/egg/encoding/transforms\n","copying build/lib.linux-x86_64-3.7/encoding/transforms/transforms.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n","copying build/lib.linux-x86_64-3.7/encoding/transforms/__init__.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n","copying build/lib.linux-x86_64-3.7/encoding/transforms/autoaug.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n","copying build/lib.linux-x86_64-3.7/encoding/transforms/get_transform.py -> build/bdist.linux-x86_64/egg/encoding/transforms\n","copying build/lib.linux-x86_64-3.7/encoding/parallel.py -> build/bdist.linux-x86_64/egg/encoding\n","copying build/lib.linux-x86_64-3.7/encoding/__init__.py -> build/bdist.linux-x86_64/egg/encoding\n","creating build/bdist.linux-x86_64/egg/encoding/lib\n","creating build/bdist.linux-x86_64/egg/encoding/lib/cpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/syncbn_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/operator.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/rectify_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/nms_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/operator.h -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/roi_align_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/cpu/encoding_cpu.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/cpu\n","creating build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/operator.cpp -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/device_tensor.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/rectify_cuda.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/encoding_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/activation_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/operator.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/roi_align_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/lib_ssd.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/common.h -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/syncbn_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/lib/gpu/nms_kernel.cu -> build/bdist.linux-x86_64/egg/encoding/lib/gpu\n","copying build/lib.linux-x86_64-3.7/encoding/gpu.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/encoding\n","copying build/lib.linux-x86_64-3.7/encoding/version.py -> build/bdist.linux-x86_64/egg/encoding\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/customize.py to customize.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/syncbn.py to syncbn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/dist_syncbn.py to dist_syncbn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/encoding.py to encoding.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/functions/rectify.py to rectify.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/cityscapes.py to cityscapes.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pascal_aug.py to pascal_aug.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/imagenet.py to imagenet.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pcontext.py to pcontext.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/pascal_voc.py to pascal_voc.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/ade20k.py to ade20k.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/base.py to base.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/hpw18.py to hpw18.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/folder.py to folder.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/minc.py to minc.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/cityscapescoarse.py to cityscapescoarse.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/datasets/coco.py to coco.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/encnet.py to encnet.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/fcn.py to fcn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/fcfpn.py to fcfpn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/upernet.py to upernet.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/base.py to base.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/atten.py to atten.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/deeplab.py to deeplab.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/sseg/psp.py to psp.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/model_store.py to model_store.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/deepten.py to deepten.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/wideresnet.py to wideresnet.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/xception.py to xception.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnext.py to resnext.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnest.py to resnest.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnet_variants.py to resnet_variants.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/backbone/resnet.py to resnet.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/models/model_zoo.py to model_zoo.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/customize.py to customize.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/syncbn.py to syncbn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/attention.py to attention.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/loss.py to loss.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/encoding.py to encoding.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/rectify.py to rectify.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/splat.py to splat.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/nn/dropblock.py to dropblock.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/pallete.py to pallete.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/presets.py to presets.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/files.py to files.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/metrics.py to metrics.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/lr_scheduler.py to lr_scheduler.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/dist_helper.py to dist_helper.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/misc.py to misc.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/train_helper.py to train_helper.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/utils/precise_bn.py to precise_bn.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/transforms.py to transforms.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/autoaug.py to autoaug.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/transforms/get_transform.py to get_transform.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/parallel.py to parallel.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/version.py to version.cpython-37.pyc\n","creating stub loader for encoding/cpu.cpython-37m-x86_64-linux-gnu.so\n","creating stub loader for encoding/gpu.cpython-37m-x86_64-linux-gnu.so\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/cpu.py to cpu.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/encoding/gpu.py to gpu.cpython-37.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying torch_encoding.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying torch_encoding.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying torch_encoding.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying torch_encoding.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying torch_encoding.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n","zip_safe flag not set; analyzing archive contents...\n","encoding.__pycache__.cpu.cpython-37: module references __file__\n","encoding.__pycache__.gpu.cpython-37: module references __file__\n","creating dist\n","creating 'dist/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg\n","creating /usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg\n","Extracting torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n","Adding torch-encoding 1.2.2b20210412 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg\n","Processing dependencies for torch-encoding==1.2.2b20210412\n","Searching for portalocker\n","Reading https://pypi.org/simple/portalocker/\n","Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl#sha256=1d43fd8223e1743f5725e8910f69e7a45858ffd298e19252633ac903eafd83bc\n","Best match: portalocker 2.3.0\n","Processing portalocker-2.3.0-py2.py3-none-any.whl\n","Installing portalocker-2.3.0-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding portalocker 2.3.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/portalocker-2.3.0-py3.7.egg\n","Searching for nose\n","Reading https://pypi.org/simple/nose/\n","Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl#sha256=9ff7c6cc443f8c51994b34a667bbcf45afd6d945be7477b52e97516fd17c53ac\n","Best match: nose 1.3.7\n","Processing nose-1.3.7-py3-none-any.whl\n","Installing nose-1.3.7-py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding nose 1.3.7 to easy-install.pth file\n","Installing nosetests script to /usr/local/bin\n","Installing nosetests-3.4 script to /usr/local/bin\n","\n","Installed /usr/local/lib/python3.7/dist-packages/nose-1.3.7-py3.7.egg\n","Searching for requests==2.23.0\n","Best match: requests 2.23.0\n","Adding requests 2.23.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for scipy==1.4.1\n","Best match: scipy 1.4.1\n","Adding scipy 1.4.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for Pillow==7.1.2\n","Best match: Pillow 7.1.2\n","Adding Pillow 7.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for torchvision==0.9.1+cu101\n","Best match: torchvision 0.9.1+cu101\n","Adding torchvision 0.9.1+cu101 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for torch==1.8.1+cu101\n","Best match: torch 1.8.1+cu101\n","Adding torch 1.8.1+cu101 to easy-install.pth file\n","Installing convert-caffe2-to-onnx script to /usr/local/bin\n","Installing convert-onnx-to-caffe2 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for tqdm==4.41.1\n","Best match: tqdm 4.41.1\n","Adding tqdm 4.41.1 to easy-install.pth file\n","Installing tqdm script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for numpy==1.19.5\n","Best match: numpy 1.19.5\n","Adding numpy 1.19.5 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.7 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for idna==2.10\n","Best match: idna 2.10\n","Adding idna 2.10 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for urllib3==1.24.3\n","Best match: urllib3 1.24.3\n","Adding urllib3 1.24.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for certifi==2020.12.5\n","Best match: certifi 2020.12.5\n","Adding certifi 2020.12.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for chardet==3.0.4\n","Best match: chardet 3.0.4\n","Adding chardet 3.0.4 to easy-install.pth file\n","Installing chardetect script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for typing-extensions==3.7.4.3\n","Best match: typing-extensions 3.7.4.3\n","Adding typing-extensions 3.7.4.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Finished processing dependencies for torch-encoding==1.2.2b20210412\n","Collecting git+https://github.com/zhanghang1989/PyTorch-Encoding/\n","  Cloning https://github.com/zhanghang1989/PyTorch-Encoding/ to /tmp/pip-req-build-ylcn2527\n","  Running command git clone -q https://github.com/zhanghang1989/PyTorch-Encoding/ /tmp/pip-req-build-ylcn2527\n","Requirement already satisfied (use --upgrade to upgrade): torch-encoding==1.2.2b20210412 from git+https://github.com/zhanghang1989/PyTorch-Encoding/ in /usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210412) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210412) (4.41.1)\n","Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages/nose-1.3.7-py3.7.egg (from torch-encoding==1.2.2b20210412) (1.3.7)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages/portalocker-2.3.0-py3.7.egg (from torch-encoding==1.2.2b20210412) (2.3.0)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210412) (1.8.1+cu101)\n","Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210412) (0.9.1+cu101)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210412) (7.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210412) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210412) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->torch-encoding==1.2.2b20210412) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210412) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210412) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210412) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210412) (3.0.4)\n","Building wheels for collected packages: torch-encoding\n","  Building wheel for torch-encoding (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-encoding: filename=torch_encoding-1.2.2b20210412-cp37-cp37m-linux_x86_64.whl size=8227537 sha256=c5945979404566c5ae965e994e37249f6aada15968524f7aa30daf4f409efca2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-6kb8dadq/wheels/f8/4f/46/924a4c89ee95252b34c3e257f1de2664a053e52c5aa5013d4a\n","Successfully built torch-encoding\n","Collecting git+https://github.com/facebookresearch/fvcore.git\n","  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-vhqlgaa4\n","  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-vhqlgaa4\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (1.19.5)\n","Collecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Collecting pyyaml>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 645kB 5.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (4.41.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (1.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (7.1.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (0.8.9)\n","Collecting iopath>=0.1.7\n","  Downloading https://files.pythonhosted.org/packages/21/d0/22104caed16fa41382702fed959f4a9b088b2f905e7a82e4483180a2ec2a/iopath-0.1.8-py3-none-any.whl\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages/portalocker-2.3.0-py3.7.egg (from iopath>=0.1.7->fvcore==0.1.5) (2.3.0)\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5-cp37-none-any.whl size=62860 sha256=a2e48dacb14b25b3167e4f4e0dc5cddf6688e3466933f34a76dee98fe1543663\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-iba1aak6/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n","Successfully built fvcore\n","Installing collected packages: pyyaml, yacs, iopath, fvcore\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed fvcore-0.1.5 iopath-0.1.8 pyyaml-5.4.1 yacs-0.1.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CJN6SRaU-pxb","colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["173df37a78b94d3c904185044106384c","f6459ecd807843c180d21f37a95942a2","a0ccd21e07704d048b45a4bbfd755f59","3cc7197d40c54b6e90ea8777e25cbd24","f739ca0f9a7e4cc294137f56fd40fed0","c412a943ec9c4e79a8526625c873e083","7646d40ed0fc423099f92a6b6c124e04","4375ad4aed06401bbfe134422722d63f"]},"executionInfo":{"status":"ok","timestamp":1618202732165,"user_tz":240,"elapsed":963281,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"3fdcd35b-cdfa-4ab4-e451-a980d634829c"},"source":["import torch\n","# get list of models\n","torch.hub.list('zhanghang1989/ResNeSt', force_reload=True)\n","\n","# load pretrained models, using ResNeSt-50 as an example\n","model = torch.hub.load('zhanghang1989/ResNeSt', 'resnest50', pretrained=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/zhanghang1989/ResNeSt/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n","Using cache found in /root/.cache/torch/hub/zhanghang1989_ResNeSt_master\n","Downloading: \"https://s3.us-west-1.wasabisys.com/resnest/torch/resnest50-528c19ca.pth\" to /root/.cache/torch/hub/checkpoints/resnest50-528c19ca.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"173df37a78b94d3c904185044106384c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=110273258.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bbnq6oNH2k2","executionInfo":{"status":"ok","timestamp":1618203338460,"user_tz":240,"elapsed":1569568,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"65dc63ad-4014-49b4-af04-6d867d32a3d8"},"source":["!python /content/PyTorch-Encoding/scripts/prepare_ade20k.py"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading /root/.encoding/data/downloads/ADEChallengeData2016.zip from http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip...\n","944710KB [08:05, 1946.51KB/s]                \n","Downloading /root/.encoding/data/downloads/release_test.zip from http://data.csail.mit.edu/places/ADEchallenge/release_test.zip...\n","100% 206856/206856 [01:40<00:00, 2066.73KB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-yJnxDiGLasG","executionInfo":{"status":"ok","timestamp":1618204196774,"user_tz":240,"elapsed":712721,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"a7e6b6a5-53ed-4722-d305-ea7f72e81a7b"},"source":["!python /content/PyTorch-Encoding/experiments/segmentation/test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt50_ADE --test-val"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=False, export=None, model='encnet', model_zoo='DeepLab_ResNeSt50_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=True, train_split='train', verify=None, workers=16)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","DeepLabV3(\n","  (pretrained): ResNet(\n","    (conv1): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): GlobalAvgPool2d()\n","    (fc): None\n","  )\n","  (head): DeepLabV3Head(\n","    (aspp): ASPP_Module(\n","      (b0): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b1): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b2): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b3): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b4): AsppPooling(\n","        (gap): Sequential(\n","          (0): AdaptiveAvgPool2d(output_size=1)\n","          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): ReLU(inplace=True)\n","        )\n","      )\n","      (project): Sequential(\n","        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Dropout2d(p=0.5, inplace=False)\n","      )\n","    )\n","    (block): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (auxlayer): FCNHead(\n","    (conv5): Sequential(\n","      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","MultiEvalModule: base_size 520, crop_size 480\n"," 12% 231/2000 [11:46<1:25:00,  2.88s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f510845a170>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 140, in join\n","    res = self._popen.wait(timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n","    if not wait([self.sentinel], timeout):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt: \n","Traceback (most recent call last):\n","  File \"/content/PyTorch-Encoding/experiments/segmentation/test.py\", line 199, in <module>\n","    test(args)\n","  File \"/content/PyTorch-Encoding/experiments/segmentation/test.py\", line 173, in test\n","    outputs = evaluator.parallel_forward(image)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg/encoding/models/sseg/base.py\", line 138, in parallel_forward\n","    outputs = self.parallel_apply(replicas, inputs, kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 177, in parallel_apply\n","    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/parallel_apply.py\", line 80, in parallel_apply\n","    _worker(0, modules[0], inputs[0], kwargs_tup[0], devices[0])\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n","    output = module(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg/encoding/models/sseg/base.py\", line 180, in forward\n","    outputs = module_inference(self.module, pad_img, self.flip)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg/encoding/models/sseg/base.py\", line 223, in module_inference\n","    output = module.evaluate(image)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg/encoding/models/sseg/base.py\", line 101, in evaluate\n","    pred = self.forward(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg/encoding/models/sseg/deeplab.py\", line 47, in forward\n","    c1, c2, c3, c4 = self.base_forward(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg/encoding/models/sseg/base.py\", line 95, in base_forward\n","    c2 = self.pretrained.layer2(c1)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 119, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg/encoding/models/backbone/resnet.py\", line 95, in forward\n","    out = self.conv2(out)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch_encoding-1.2.2b20210412-py3.7-linux-x86_64.egg/encoding/nn/splat.py\", line 57, in forward\n","    splited = torch.split(x, channel//self.radix, dim=1)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/functional.py\", line 156, in split\n","    return tensor.split(split_size_or_sections, dim)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 485, in split\n","    def split(self, split_size, dim=0):\n","KeyboardInterrupt\n"," 12% 231/2000 [11:46<1:30:12,  3.06s/it]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HlTHTf1Ze-w0","executionInfo":{"status":"ok","timestamp":1618204219908,"user_tz":240,"elapsed":1480,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}}},"source":["%cp -r /content/PyTorch-Encoding/outdir /content/drive/MyDrive/data/ade20k"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"W91zijvsUxL2"},"source":["%cp -r ~/content/leftImg8bit /content/drive/MyDrive/data/citys/leftImg8bit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRAXpGXhG1hm","executionInfo":{"status":"ok","timestamp":1617920911556,"user_tz":240,"elapsed":4279264,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"5c80664c-b741-4638-d6a6-f45acb460551"},"source":["!python /content/PyTorch-Encoding/experiments/segmentation/test.py --dataset ADE20K --model-zoo FCN_ResNeSt50_ADE --eval"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='FCN_ResNeSt50_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Model file /root/.encoding/models/resnest50-fb9de5b3.pth is not found. Downloading.\n","Downloading /root/.encoding/models/resnest50-fb9de5b3.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest50-fb9de5b3.zip...\n","100% 107689/107689 [00:10<00:00, 10506.01KB/s]\n","Model file /root/.encoding/models/fcn_resnest50_ade-4aba491a.pth is not found. Downloading.\n","Downloading /root/.encoding/models/fcn_resnest50_ade-4aba491a.zip from https://s3.us-west-1.wasabisys.com/encoding/models/fcn_resnest50_ade-4aba491a.zip...\n","146246KB [00:11, 12712.00KB/s]                \n","FCN(\n","  (pretrained): ResNet(\n","    (conv1): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): SyncBatchNorm(sync=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): SyncBatchNorm(sync=False)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (bn1): SyncBatchNorm(sync=False)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): SyncBatchNorm(sync=False)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): SyncBatchNorm(sync=False)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): SyncBatchNorm(sync=False)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): SyncBatchNorm(sync=False)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): SyncBatchNorm(sync=False)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): SyncBatchNorm(sync=False)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): SyncBatchNorm(sync=False)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): SyncBatchNorm(sync=False)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): GlobalAvgPool2d()\n","    (fc): None\n","  )\n","  (head): FCNHead(\n","    (conv5): Sequential(\n","      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): SyncBatchNorm(sync=False)\n","      (2): ReLU()\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(512, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (auxlayer): FCNHead(\n","    (conv5): Sequential(\n","      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): SyncBatchNorm(sync=False)\n","      (2): ReLU()\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","MultiEvalModule: base_size 520, crop_size 480\n","pixAcc: 0.8018, mIoU: 0.4294: 100% 2000/2000 [1:12:55<00:00,  2.19s/it]\n","pixAcc: 0.8018, mIoU: 0.4294\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCqM2kvKk4Y4","executionInfo":{"status":"ok","timestamp":1617927024479,"user_tz":240,"elapsed":6111914,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"b14b49ed-ed35-4caa-a1c7-2470cd2d8069"},"source":["!python /content/PyTorch-Encoding/experiments/segmentation/test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt50_ADE --eval"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt50_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Model file /root/.encoding/models/deeplab_resnest50_ade-2225f09d.pth is not found. Downloading.\n","Downloading /root/.encoding/models/deeplab_resnest50_ade-2225f09d.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest50_ade-2225f09d.zip...\n","172229KB [00:14, 12175.46KB/s]                \n","DeepLabV3(\n","  (pretrained): ResNet(\n","    (conv1): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): GlobalAvgPool2d()\n","    (fc): None\n","  )\n","  (head): DeepLabV3Head(\n","    (aspp): ASPP_Module(\n","      (b0): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b1): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b2): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b3): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b4): AsppPooling(\n","        (gap): Sequential(\n","          (0): AdaptiveAvgPool2d(output_size=1)\n","          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): ReLU(inplace=True)\n","        )\n","      )\n","      (project): Sequential(\n","        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Dropout2d(p=0.5, inplace=False)\n","      )\n","    )\n","    (block): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (auxlayer): FCNHead(\n","    (conv5): Sequential(\n","      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","MultiEvalModule: base_size 520, crop_size 480\n","pixAcc: 0.8117, mIoU: 0.4512: 100% 2000/2000 [1:41:28<00:00,  3.04s/it]\n","pixAcc: 0.8117, mIoU: 0.4512\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2j1nHBvk4m-","executionInfo":{"status":"ok","timestamp":1617936426124,"user_tz":240,"elapsed":15513553,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"66da6f99-afdb-465f-ebd4-7a4d3c9b3225"},"source":["!python /content/PyTorch-Encoding/experiments/segmentation/test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt101_ADE --eval"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt101_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Model file /root/.encoding/models/resnest101-966fb78c.pth is not found. Downloading.\n","Downloading /root/.encoding/models/resnest101-966fb78c.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest101-966fb78c.zip...\n","189242KB [00:15, 11848.58KB/s]                \n","Model file /root/.encoding/models/deeplab_resnest101_ade-06ca799c.pth is not found. Downloading.\n","Downloading /root/.encoding/models/deeplab_resnest101_ade-06ca799c.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest101_ade-06ca799c.zip...\n","100% 253789/253789 [00:17<00:00, 14816.05KB/s]\n","DeepLabV3(\n","  (pretrained): ResNet(\n","    (conv1): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): GlobalAvgPool2d()\n","    (fc): None\n","  )\n","  (head): DeepLabV3Head(\n","    (aspp): ASPP_Module(\n","      (b0): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b1): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b2): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b3): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b4): AsppPooling(\n","        (gap): Sequential(\n","          (0): AdaptiveAvgPool2d(output_size=1)\n","          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): ReLU(inplace=True)\n","        )\n","      )\n","      (project): Sequential(\n","        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Dropout2d(p=0.5, inplace=False)\n","      )\n","    )\n","    (block): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (auxlayer): FCNHead(\n","    (conv5): Sequential(\n","      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","MultiEvalModule: base_size 520, crop_size 480\n","pixAcc: 0.8207, mIoU: 0.4691: 100% 2000/2000 [2:35:58<00:00,  4.68s/it]\n","pixAcc: 0.8207, mIoU: 0.4691\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QO5BBueEk4xJ","executionInfo":{"status":"ok","timestamp":1617949703820,"user_tz":240,"elapsed":9912244,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"318e570c-5a8a-4415-de0b-52c21ad703b6"},"source":["!python /content/PyTorch-Encoding/experiments/segmentation/test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt200_ADE --eval"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt200_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Model file /root/.encoding/models/resnest200-d7fd712f.pth is not found. Downloading.\n","Downloading /root/.encoding/models/resnest200-d7fd712f.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest200-d7fd712f.zip...\n","100% 275389/275389 [00:17<00:00, 15465.50KB/s]\n","Model file /root/.encoding/models/deeplab_resnest200_ade-7b9e7d3e.pth is not found. Downloading.\n","Downloading /root/.encoding/models/deeplab_resnest200_ade-7b9e7d3e.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest200_ade-7b9e7d3e.zip...\n","100% 339949/339949 [00:22<00:00, 15277.56KB/s]\n","DeepLabV3(\n","  (pretrained): ResNet(\n","    (conv1): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (23): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (23): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (24): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (25): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (26): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (27): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (28): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (29): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (30): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (31): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (32): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (33): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (34): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (35): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): GlobalAvgPool2d()\n","    (fc): None\n","  )\n","  (head): DeepLabV3Head(\n","    (aspp): ASPP_Module(\n","      (b0): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b1): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b2): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b3): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b4): AsppPooling(\n","        (gap): Sequential(\n","          (0): AdaptiveAvgPool2d(output_size=1)\n","          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): ReLU(inplace=True)\n","        )\n","      )\n","      (project): Sequential(\n","        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Dropout2d(p=0.5, inplace=False)\n","      )\n","    )\n","    (block): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (auxlayer): FCNHead(\n","    (conv5): Sequential(\n","      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","MultiEvalModule: base_size 520, crop_size 480\n","pixAcc: 0.8245, mIoU: 0.4836: 100% 2000/2000 [3:40:26<00:00,  6.61s/it]\n","pixAcc: 0.8245, mIoU: 0.4836\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3IxqZmQnlKB2","executionInfo":{"status":"ok","timestamp":1617968468232,"user_tz":240,"elapsed":18764442,"user":{"displayName":"Jennifer Kong","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMOboZ-lNXyQevzFCrLPSrVLE7EEchMWPYgbCmnA=s64","userId":"00781852712927674701"}},"outputId":"7ff817e6-d2d2-4fd6-cafb-822efded9e50"},"source":["!python /content/PyTorch-Encoding/experiments/segmentation/test.py --dataset ADE20K --model-zoo DeepLab_ResNeSt269_ADE --eval"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(acc_bn=False, aux=False, backbone='resnet50', base_size=520, batch_size=16, crop_size=480, cuda=True, dataset='ADE20K', eval=True, export=None, model='encnet', model_zoo='DeepLab_ResNeSt269_ADE', no_cuda=False, no_val=False, resume=None, se_loss=False, se_weight=0.2, seed=1, test_batch_size=16, test_folder=None, test_val=False, train_split='train', verify=None, workers=16)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Model file /root/.encoding/models/resnest269-51ae5f19.pth is not found. Downloading.\n","Downloading /root/.encoding/models/resnest269-51ae5f19.zip from https://s3.us-west-1.wasabisys.com/encoding/models/resnest269-51ae5f19.zip...\n","100% 434964/434964 [00:26<00:00, 16613.04KB/s]\n","Model file /root/.encoding/models/deeplab_resnest269_ade-0074dd10.pth is not found. Downloading.\n","Downloading /root/.encoding/models/deeplab_resnest269_ade-0074dd10.zip from https://s3.us-west-1.wasabisys.com/encoding/models/deeplab_resnest269_ade-0074dd10.zip...\n","499544KB [00:28, 17568.80KB/s]               \n","DeepLabV3(\n","  (pretrained): ResNet(\n","    (conv1): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (23): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (24): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (25): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (26): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (27): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (28): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (29): Bottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (8): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (9): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (10): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (11): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (12): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (13): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (14): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (15): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (16): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (17): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (18): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (19): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (20): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (21): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (22): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (23): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (24): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (25): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (26): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (27): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (28): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (29): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (30): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (31): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (32): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (33): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (34): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (35): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (36): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (37): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (38): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (39): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (40): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (41): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (42): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (43): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (44): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (45): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (46): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (47): Bottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): Bottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (avd_layer): AvgPool2d(kernel_size=3, stride=1, padding=1)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n","          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (2): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (3): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (4): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (5): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (6): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","      (7): Bottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv2): SplAtConv2d(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): rSoftMax()\n","        )\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","      )\n","    )\n","    (avgpool): GlobalAvgPool2d()\n","    (fc): None\n","  )\n","  (head): DeepLabV3Head(\n","    (aspp): ASPP_Module(\n","      (b0): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b1): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b2): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b3): Sequential(\n","        (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","      (b4): AsppPooling(\n","        (gap): Sequential(\n","          (0): AdaptiveAvgPool2d(output_size=1)\n","          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (3): ReLU(inplace=True)\n","        )\n","      )\n","      (project): Sequential(\n","        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): Dropout2d(p=0.5, inplace=False)\n","      )\n","    )\n","    (block): Sequential(\n","      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (auxlayer): FCNHead(\n","    (conv5): Sequential(\n","      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","      (3): Dropout(p=0.1, inplace=False)\n","      (4): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","MultiEvalModule: base_size 520, crop_size 480\n","pixAcc: 0.8262, mIoU: 0.4760: 100% 2000/2000 [5:11:34<00:00,  9.35s/it]\n","pixAcc: 0.8262, mIoU: 0.4760\n"],"name":"stdout"}]}]}