{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMSA_ResNest",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coazcv88pE5p"
      },
      "source": [
        "# HMSA - Combining the HMSA and ResNest Architectures\n",
        "\n",
        "\n",
        "## Before Running the Code\n",
        "1. Ensure that the runtime is set to GPU!\n",
        "2. Ensure that the Colab VM is in the same region as the Google Cloud Storage Buckets (which are `US-multi-region`).\n",
        "  - This minimizes costs, as Google charges for network egress.\n",
        "  - The Colab region can be checked by running the cell below.\n",
        "  - Perform a factory reset of the runtime until the runtime is in the US."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42eL1zsKntsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d021e42b-6714-4013-aa1d-cef4bb5ebea9"
      },
      "source": [
        "!curl ipinfo.io"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ip\": \"35.199.18.110\",\n",
            "  \"hostname\": \"110.18.199.35.bc.googleusercontent.com\",\n",
            "  \"city\": \"Washington\",\n",
            "  \"region\": \"Washington, D.C.\",\n",
            "  \"country\": \"US\",\n",
            "  \"loc\": \"38.8951,-77.0364\",\n",
            "  \"org\": \"AS15169 Google LLC\",\n",
            "  \"postal\": \"20045\",\n",
            "  \"timezone\": \"America/New_York\",\n",
            "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_txd-_uhJ_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779061ac-2aaf-4c37-cd90-c2301b3d6f96"
      },
      "source": [
        "# check GPU specs\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-1946430a-41c4-8341-ae23-784393f7ce9d)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvgCZfO7pSGG"
      },
      "source": [
        "## 1. Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E3xAHObqhYX"
      },
      "source": [
        "### 1.1. Clone Git Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ajJnUTCs5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d48f16-8079-41aa-c8c2-2fce5d399703"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIt0eJgpoUqe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39ce1a90-2191-4d12-babc-8f674d210bdf"
      },
      "source": [
        "%cd /content/drive/MyDrive/CSC413/\n",
        "!git clone https://github.com/Brian0615/CSC413FinalProject.git\n",
        "%cd /content/drive/MyDrive/CSC413/CSC413FinalProject/\n",
        "!git checkout brian"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSC413\n",
            "fatal: destination path 'CSC413FinalProject' already exists and is not an empty directory.\n",
            "/content/drive/MyDrive/CSC413/CSC413FinalProject\n",
            "M\tHMSA/train.py\n",
            "M\tPyTorch-Encoding/docs/source/_static/img/upconv.png\n",
            "M\tPyTorch-Encoding/tests/lint.py\n",
            "Branch 'brian' set up to track remote branch 'brian' from 'origin'.\n",
            "Switched to a new branch 'brian'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89129JwLcp6F"
      },
      "source": [
        "%cd /content/drive/MyDrive/CSC413/CSC413FinalProject/\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLf5IHXi8tnY"
      },
      "source": [
        "###1.2. Download Cityscapes Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6cUtIXPS7y9"
      },
      "source": [
        "%cd /content\n",
        "!mkdir cityscapes\n",
        "%cd cityscapes\n",
        "!mkdir leftImg8bit_trainvaltest\n",
        "!mkdir gtFine_trainvaltest\n",
        "%cd leftImg8bit_trainvaltest\n",
        "!mkdir leftImg8bit\n",
        "%cd leftImg8bit\n",
        "!mkdir train\n",
        "!mkdir val\n",
        "!mkdir test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7blWV422fc_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c61c160-4a1a-4411-ed04-5a62830d9851"
      },
      "source": [
        "!gcloud init"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome! This command will take you through the configuration of gcloud.\n",
            "\n",
            "Settings from your current configuration [default] are:\n",
            "component_manager:\n",
            "  disable_update_check: 'True'\n",
            "compute:\n",
            "  gce_metadata_read_timeout_sec: '0'\n",
            "\n",
            "Pick configuration to use:\n",
            " [1] Re-initialize this configuration [default] with new settings \n",
            " [2] Create a new configuration\n",
            "Please enter your numeric choice:  1\n",
            "\n",
            "Your current configuration has been set to: [default]\n",
            "\n",
            "You can skip diagnostics next time by using the following flag:\n",
            "  gcloud init --skip-diagnostics\n",
            "\n",
            "Network diagnostic detects and fixes local network connection issues.\n",
            "Reachability Check passed.\n",
            "Network diagnostic passed (1/1 checks passed).\n",
            "\n",
            "You must log in to continue. Would you like to log in (Y/n)?  y\n",
            "\n",
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=KdqGCaRNtHdrXYz9279IPK1NxsiJyt&prompt=consent&access_type=offline&code_challenge=2xJ8lkQRKeAGDkHGAy5VpPwQ1kD8-I1KImn4Jn68GXU&code_challenge_method=S256\n",
            "\n",
            "Enter verification code: 4/1AY0e-g6HtlltMRnrtTnwkd_wUyKmNaH7X05t3SJ-YPKwOLn1Tgn9mABwGBQ\n",
            "You are logged in as: [brianps.lam@mail.utoronto.ca].\n",
            "\n",
            "Pick cloud project to use: \n",
            " [1] csc413-final-project-2021\n",
            " [2] Create a new project\n",
            "Please enter numeric choice or text value (must exactly match list \n",
            "item):  1\n",
            "\n",
            "Your current project has been set to: [csc413-final-project-2021].\n",
            "\n",
            "Do you want to configure a default Compute Region and Zone? (Y/n)?  n\n",
            "\n",
            "Your Google Cloud SDK is configured and ready to use!\n",
            "\n",
            "* Commands that require authentication will use brianps.lam@mail.utoronto.ca by default\n",
            "* Commands will reference project `csc413-final-project-2021` by default\n",
            "Run `gcloud help config` to learn how to change individual settings\n",
            "\n",
            "This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.\n",
            "Run `gcloud topic configurations` to learn more.\n",
            "\n",
            "Some things to try next:\n",
            "\n",
            "* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.\n",
            "* Run `gcloud topic --help` to learn about advanced features of the SDK like arg files and output formatting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjH6Xi8Sm1bX"
      },
      "source": [
        "!gsutil -m cp -r gs://csc413-final-project-cityscapes-data/gtFine /content/cityscapes/gtFine_trainvaltest/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0iG1pOMSNK0"
      },
      "source": [
        "!gsutil -m cp -r gs://csc413-final-project-cityscapes-data/leftImg8bit/train/ /content/cityscapes/leftImg8bit_trainvaltest/leftImg8bit/\n",
        "!gsutil -m cp -r gs://csc413-final-project-cityscapes-data/leftImg8bit/val/ /content/cityscapes/leftImg8bit_trainvaltest/leftImg8bit/\n",
        "!gsutil -m cp -r gs://csc413-final-project-cityscapes-data/leftImg8bit/test/ /content/cityscapes/leftImg8bit_trainvaltest/leftImg8bit/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZptIStcsch7r"
      },
      "source": [
        "### 1.3. Download Weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOqsFVNDjQoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf659581-c735-4b8a-ac28-d9cb004b651c"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/data/seg_weights/\n",
        "!gsutil -m cp gs://csc413-final-project-hmsa-weights/original_weights/ocrnet.HRNet_industrious-chicken.pth /content/drive/MyDrive/data/seg_weights/\n",
        "!gsutil -m cp gs://csc413-final-project-hmsa-weights/original_weights/hrnetv2_w48_imagenet_pretrained.pth //content/drive/MyDrive/data/seg_weights/"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/data/seg_weights/’: File exists\n",
            "Copying gs://csc413-final-project-hmsa-weights/original_weights/hrnetv2_w48_imagenet_pretrained.pth...\n",
            "| [1/1 files][296.2 MiB/296.2 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/296.2 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekgqR0rhT6DT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36cd7b52-a139-4e29-dc44-98558f1a9bbe"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/data/uniform_centroids/\n",
        "!gsutil -m cp gs://csc413-final-project-cityscapes-data/uniform_centroids/* /content/drive/MyDrive/data/uniform_centroids/"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/data/uniform_centroids/’: File exists\n",
            "Copying gs://csc413-final-project-cityscapes-data/uniform_centroids/cityscapes_cv0_tile1024.json...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wj7QGFrqI7E"
      },
      "source": [
        "### 1.4. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EboP9tppocm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f656e5da-15b4-4516-edbf-21830742b40e"
      },
      "source": [
        "# install basic dependencies\n",
        "!pip install runx==0.0.6 numpy sklearn h5py jupyter scikit-image pillow piexif cffi tqdm dominate opencv-python nose ninja\n",
        "!apt-get update\n",
        "!apt-get install libgtk2.0-dev -y\n",
        "!rm -rf /var/lib/apt/lists/*"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting runx==0.0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/4f/757e3a0bdf6c94f6d2571cf5ab6fc3812535f0bf918fb2609837eca1bd0a/runx-0.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting piexif\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/d8/6f63147dd73373d051c5eb049ecd841207f898f50a5a1d4378594178f6cf/piexif-1.1.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (1.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 30.7MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from runx==0.0.6) (0.8.9)\n",
            "Collecting coolname>=1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/43/64c0cec51944924f44c0788c329a2c6fde061428c97d7cba73de177ececd/coolname-1.1.0-py2.py3-none-any.whl\n",
            "Collecting tensorboardX>=1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 52.7MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 56.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py) (1.15.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter) (7.6.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.0.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter) (5.6.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi) (2.20)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.4->runx==0.0.6) (3.12.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.0.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.0.5)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.1.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter) (2.6.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter) (1.0.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter) (5.1.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter) (3.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (2.11.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (0.2.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (1.5.0)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (4.7.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter) (0.9.4)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (22.0.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter) (1.9.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (3.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter) (0.4.4)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX>=1.4->runx==0.0.6) (54.2.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (0.2.5)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter) (2.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
            "Installing collected packages: coolname, tensorboardX, pyyaml, runx, piexif, dominate, nose, ninja\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed coolname-1.1.0 dominate-2.6.0 ninja-1.10.0.post2 nose-1.3.7 piexif-1.1.3 pyyaml-5.4.1 runx-0.0.6 tensorboardX-2.2\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [24.5 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,112 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [395 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,408 kB]\n",
            "Hit:18 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [739 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,755 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [425 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,180 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,542 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [898 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [31.4 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [39.5 kB]\n",
            "Fetched 12.8 MB in 3s (4,440 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev debhelper dh-autoreconf\n",
            "  dh-strip-nondeterminism file gettext gettext-base gir1.2-atk-1.0\n",
            "  gir1.2-freedesktop gir1.2-gdkpixbuf-2.0 gir1.2-gtk-2.0 gir1.2-pango-1.0\n",
            "  intltool-debian libarchive-cpio-perl libarchive-zip-perl libatk1.0-dev\n",
            "  libcairo-script-interpreter2 libcairo2-dev libfile-stripnondeterminism-perl\n",
            "  libgail-common libgail18 libgdk-pixbuf2.0-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libmagic-mgc libmagic1 libmail-sendmail-perl\n",
            "  libpango1.0-dev libpangoxft-1.0-0 libpixman-1-dev libsigsegv2\n",
            "  libsys-hostname-long-perl libtimedate-perl libtool libxcb-shm0-dev\n",
            "  libxcomposite-dev libxcursor-dev libxinerama-dev libxml2-utils libxrandr-dev\n",
            "  m4 po-debconf x11proto-composite-dev x11proto-randr-dev\n",
            "  x11proto-xinerama-dev\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc dh-make dwz gettext-doc\n",
            "  libasprintf-dev libgettextpo-dev libcairo2-doc gvfs libgtk2.0-doc\n",
            "  imagemagick libpango1.0-doc libtool-doc gcj-jdk m4-doc libmail-box-perl\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autopoint autotools-dev debhelper dh-autoreconf\n",
            "  dh-strip-nondeterminism file gettext gettext-base gir1.2-atk-1.0\n",
            "  gir1.2-freedesktop gir1.2-gdkpixbuf-2.0 gir1.2-gtk-2.0 gir1.2-pango-1.0\n",
            "  intltool-debian libarchive-cpio-perl libarchive-zip-perl libatk1.0-dev\n",
            "  libcairo-script-interpreter2 libcairo2-dev libfile-stripnondeterminism-perl\n",
            "  libgail-common libgail18 libgdk-pixbuf2.0-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libgtk2.0-dev libmagic-mgc libmagic1 libmail-sendmail-perl\n",
            "  libpango1.0-dev libpangoxft-1.0-0 libpixman-1-dev libsigsegv2\n",
            "  libsys-hostname-long-perl libtimedate-perl libtool libxcb-shm0-dev\n",
            "  libxcomposite-dev libxcursor-dev libxinerama-dev libxml2-utils libxrandr-dev\n",
            "  m4 po-debconf x11proto-composite-dev x11proto-randr-dev\n",
            "  x11proto-xinerama-dev\n",
            "0 upgraded, 50 newly installed, 0 to remove and 74 not upgraded.\n",
            "Need to get 11.1 MB of archives.\n",
            "After this operation, 56.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic-mgc amd64 1:5.32-2ubuntu0.4 [184 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libmagic1 amd64 1:5.32-2ubuntu0.4 [68.6 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 file amd64 1:5.32-2ubuntu0.4 [22.1 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext-base amd64 0.19.8.1-6ubuntu0.3 [113 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 autopoint all 0.19.8.1-6ubuntu0.3 [426 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtool all 2.4.6-2 [194 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-autoreconf all 17 [15.8 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libarchive-zip-perl all 1.60-1ubuntu0.1 [84.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 libfile-stripnondeterminism-perl all 0.040-1.1~build1 [13.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 libtimedate-perl all 2.3000-2 [37.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 dh-strip-nondeterminism all 0.040-1.1~build1 [5,208 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gettext amd64 0.19.8.1-6ubuntu0.3 [1,293 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 intltool-debian all 0.35.0+20060710.4 [24.9 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 po-debconf all 1.0.20 [232 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 debhelper all 11.1.6ubuntu2 [902 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-atk-1.0 amd64 2.28.1-1 [17.8 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-freedesktop amd64 1.56.1-1 [9,080 B]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gdkpixbuf-2.0 amd64 2.36.11-2 [7,748 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpangoxft-1.0-0 amd64 1.40.14-1ubuntu0.1 [15.0 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 gir1.2-pango-1.0 amd64 1.40.14-1ubuntu0.1 [21.6 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic/main amd64 gir1.2-gtk-2.0 amd64 2.24.32-1ubuntu1 [172 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic/main amd64 libarchive-cpio-perl all 0.10-1 [9,644 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk1.0-dev amd64 2.28.1-1 [79.9 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo-script-interpreter2 amd64 1.15.10-2ubuntu0.1 [53.5 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpixman-1-dev amd64 0.34.0-2 [244 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0-dev amd64 1.13-2~ubuntu18.04 [6,684 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2-dev amd64 1.15.10-2ubuntu0.1 [626 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgdk-pixbuf2.0-dev amd64 2.36.11-2 [46.8 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpango1.0-dev amd64 1.40.14-1ubuntu0.1 [288 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-xinerama-dev all 2018.4-4 [2,628 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxinerama-dev amd64 2:1.1.3-1 [8,404 B]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-randr-dev all 2018.4-4 [2,620 B]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxrandr-dev amd64 2:1.5.1-1 [24.0 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcursor-dev amd64 1:1.1.15-1 [26.5 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11proto-composite-dev all 1:2018.4-4 [2,620 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxcomposite-dev amd64 1:0.4.4-2 [9,136 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxml2-utils amd64 2.9.4+dfsg1-6.1ubuntu1.3 [35.9 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-dev amd64 2.24.32-1ubuntu1 [2,652 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsys-hostname-long-perl all 1.5-1 [11.7 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmail-sendmail-perl all 0.80-1 [22.6 kB]\n",
            "Fetched 11.1 MB in 1s (7,949 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "(Reading database ... 160983 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../01-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package file.\n",
            "Preparing to unpack .../02-file_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking file (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package gettext-base.\n",
            "Preparing to unpack .../03-gettext-base_0.19.8.1-6ubuntu0.3_amd64.deb ...\n",
            "Unpacking gettext-base (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "Preparing to unpack .../04-libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../05-m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../06-autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../07-autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../08-automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Selecting previously unselected package autopoint.\n",
            "Preparing to unpack .../09-autopoint_0.19.8.1-6ubuntu0.3_all.deb ...\n",
            "Unpacking autopoint (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package libtool.\n",
            "Preparing to unpack .../10-libtool_2.4.6-2_all.deb ...\n",
            "Unpacking libtool (2.4.6-2) ...\n",
            "Selecting previously unselected package dh-autoreconf.\n",
            "Preparing to unpack .../11-dh-autoreconf_17_all.deb ...\n",
            "Unpacking dh-autoreconf (17) ...\n",
            "Selecting previously unselected package libarchive-zip-perl.\n",
            "Preparing to unpack .../12-libarchive-zip-perl_1.60-1ubuntu0.1_all.deb ...\n",
            "Unpacking libarchive-zip-perl (1.60-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libfile-stripnondeterminism-perl.\n",
            "Preparing to unpack .../13-libfile-stripnondeterminism-perl_0.040-1.1~build1_all.deb ...\n",
            "Unpacking libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\n",
            "Selecting previously unselected package libtimedate-perl.\n",
            "Preparing to unpack .../14-libtimedate-perl_2.3000-2_all.deb ...\n",
            "Unpacking libtimedate-perl (2.3000-2) ...\n",
            "Selecting previously unselected package dh-strip-nondeterminism.\n",
            "Preparing to unpack .../15-dh-strip-nondeterminism_0.040-1.1~build1_all.deb ...\n",
            "Unpacking dh-strip-nondeterminism (0.040-1.1~build1) ...\n",
            "Selecting previously unselected package gettext.\n",
            "Preparing to unpack .../16-gettext_0.19.8.1-6ubuntu0.3_amd64.deb ...\n",
            "Unpacking gettext (0.19.8.1-6ubuntu0.3) ...\n",
            "Selecting previously unselected package intltool-debian.\n",
            "Preparing to unpack .../17-intltool-debian_0.35.0+20060710.4_all.deb ...\n",
            "Unpacking intltool-debian (0.35.0+20060710.4) ...\n",
            "Selecting previously unselected package po-debconf.\n",
            "Preparing to unpack .../18-po-debconf_1.0.20_all.deb ...\n",
            "Unpacking po-debconf (1.0.20) ...\n",
            "Selecting previously unselected package debhelper.\n",
            "Preparing to unpack .../19-debhelper_11.1.6ubuntu2_all.deb ...\n",
            "Unpacking debhelper (11.1.6ubuntu2) ...\n",
            "Selecting previously unselected package gir1.2-atk-1.0:amd64.\n",
            "Preparing to unpack .../20-gir1.2-atk-1.0_2.28.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-atk-1.0:amd64 (2.28.1-1) ...\n",
            "Selecting previously unselected package gir1.2-freedesktop:amd64.\n",
            "Preparing to unpack .../21-gir1.2-freedesktop_1.56.1-1_amd64.deb ...\n",
            "Unpacking gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Selecting previously unselected package gir1.2-gdkpixbuf-2.0:amd64.\n",
            "Preparing to unpack .../22-gir1.2-gdkpixbuf-2.0_2.36.11-2_amd64.deb ...\n",
            "Unpacking gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../23-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libpangoxft-1.0-0:amd64.\n",
            "Preparing to unpack .../24-libpangoxft-1.0-0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpangoxft-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package gir1.2-pango-1.0:amd64.\n",
            "Preparing to unpack .../25-gir1.2-pango-1.0_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking gir1.2-pango-1.0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../26-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package gir1.2-gtk-2.0.\n",
            "Preparing to unpack .../27-gir1.2-gtk-2.0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking gir1.2-gtk-2.0 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libarchive-cpio-perl.\n",
            "Preparing to unpack .../28-libarchive-cpio-perl_0.10-1_all.deb ...\n",
            "Unpacking libarchive-cpio-perl (0.10-1) ...\n",
            "Selecting previously unselected package libatk1.0-dev:amd64.\n",
            "Preparing to unpack .../29-libatk1.0-dev_2.28.1-1_amd64.deb ...\n",
            "Unpacking libatk1.0-dev:amd64 (2.28.1-1) ...\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\n",
            "Preparing to unpack .../30-libcairo-script-interpreter2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../31-libpixman-1-dev_0.34.0-2_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\n",
            "Preparing to unpack .../32-libxcb-shm0-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\n",
            "Preparing to unpack .../33-libcairo2-dev_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../34-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../35-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-dev.\n",
            "Preparing to unpack .../36-libgdk-pixbuf2.0-dev_2.36.11-2_amd64.deb ...\n",
            "Unpacking libgdk-pixbuf2.0-dev (2.36.11-2) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../37-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libpango1.0-dev.\n",
            "Preparing to unpack .../38-libpango1.0-dev_1.40.14-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpango1.0-dev (1.40.14-1ubuntu0.1) ...\n",
            "Selecting previously unselected package x11proto-xinerama-dev.\n",
            "Preparing to unpack .../39-x11proto-xinerama-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-xinerama-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxinerama-dev:amd64.\n",
            "Preparing to unpack .../40-libxinerama-dev_2%3a1.1.3-1_amd64.deb ...\n",
            "Unpacking libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Selecting previously unselected package x11proto-randr-dev.\n",
            "Preparing to unpack .../41-x11proto-randr-dev_2018.4-4_all.deb ...\n",
            "Unpacking x11proto-randr-dev (2018.4-4) ...\n",
            "Selecting previously unselected package libxrandr-dev:amd64.\n",
            "Preparing to unpack .../42-libxrandr-dev_2%3a1.5.1-1_amd64.deb ...\n",
            "Unpacking libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Selecting previously unselected package libxcursor-dev:amd64.\n",
            "Preparing to unpack .../43-libxcursor-dev_1%3a1.1.15-1_amd64.deb ...\n",
            "Unpacking libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Selecting previously unselected package x11proto-composite-dev.\n",
            "Preparing to unpack .../44-x11proto-composite-dev_1%3a2018.4-4_all.deb ...\n",
            "Unpacking x11proto-composite-dev (1:2018.4-4) ...\n",
            "Selecting previously unselected package libxcomposite-dev:amd64.\n",
            "Preparing to unpack .../45-libxcomposite-dev_1%3a0.4.4-2_amd64.deb ...\n",
            "Unpacking libxcomposite-dev:amd64 (1:0.4.4-2) ...\n",
            "Selecting previously unselected package libxml2-utils.\n",
            "Preparing to unpack .../46-libxml2-utils_2.9.4+dfsg1-6.1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libxml2-utils (2.9.4+dfsg1-6.1ubuntu1.3) ...\n",
            "Selecting previously unselected package libgtk2.0-dev.\n",
            "Preparing to unpack .../47-libgtk2.0-dev_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-dev (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libsys-hostname-long-perl.\n",
            "Preparing to unpack .../48-libsys-hostname-long-perl_1.5-1_all.deb ...\n",
            "Unpacking libsys-hostname-long-perl (1.5-1) ...\n",
            "Selecting previously unselected package libmail-sendmail-perl.\n",
            "Preparing to unpack .../49-libmail-sendmail-perl_0.80-1_all.deb ...\n",
            "Unpacking libmail-sendmail-perl (0.80-1) ...\n",
            "Setting up libxcursor-dev:amd64 (1:1.1.15-1) ...\n",
            "Setting up gir1.2-atk-1.0:amd64 (2.28.1-1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libarchive-zip-perl (1.60-1ubuntu0.1) ...\n",
            "Setting up libtimedate-perl (2.3000-2) ...\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up gir1.2-freedesktop:amd64 (1.56.1-1) ...\n",
            "Setting up libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Setting up libpangoxft-1.0-0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libxml2-utils (2.9.4+dfsg1-6.1ubuntu1.3) ...\n",
            "Setting up libarchive-cpio-perl (0.10-1) ...\n",
            "Setting up gir1.2-gdkpixbuf-2.0:amd64 (2.36.11-2) ...\n",
            "Setting up libatk1.0-dev:amd64 (2.28.1-1) ...\n",
            "Setting up gettext-base (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up gir1.2-pango-1.0:amd64 (1.40.14-1ubuntu0.1) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libsys-hostname-long-perl (1.5-1) ...\n",
            "Setting up libgdk-pixbuf2.0-dev (2.36.11-2) ...\n",
            "Setting up libmail-sendmail-perl (0.80-1) ...\n",
            "Setting up x11proto-xinerama-dev (2018.4-4) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2) ...\n",
            "Setting up x11proto-randr-dev (2018.4-4) ...\n",
            "Setting up libxinerama-dev:amd64 (2:1.1.3-1) ...\n",
            "Setting up x11proto-composite-dev (1:2018.4-4) ...\n",
            "Setting up autopoint (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up libfile-stripnondeterminism-perl (0.040-1.1~build1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libxrandr-dev:amd64 (2:1.5.1-1) ...\n",
            "Setting up libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up gettext (0.19.8.1-6ubuntu0.3) ...\n",
            "Setting up libxcomposite-dev:amd64 (1:0.4.4-2) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up file (1:5.32-2ubuntu0.4) ...\n",
            "Setting up intltool-debian (0.35.0+20060710.4) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Setting up libpango1.0-dev (1.40.14-1ubuntu0.1) ...\n",
            "Setting up gir1.2-gtk-2.0 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libtool (2.4.6-2) ...\n",
            "Setting up po-debconf (1.0.20) ...\n",
            "Setting up libgtk2.0-dev (2.24.32-1ubuntu1) ...\n",
            "Setting up dh-autoreconf (17) ...\n",
            "Setting up debhelper (11.1.6ubuntu2) ...\n",
            "Setting up dh-strip-nondeterminism (0.040-1.1~build1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLIl6-r9teWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ff0cd2-0e71-4cd6-ffc1-9e746638a9ce"
      },
      "source": [
        "# change cuda version to 10.1\n",
        "%cd /usr/local/\n",
        "!rm -rf cuda\n",
        "!ln -s /usr/local/cuda-10.1 /usr/local/cuda  # replace symlink to cuda-11.0 with cuda-10.1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxr1rIG1SD34",
        "outputId": "5ab1bb2a-b543-4b51-d08a-5b285081d731"
      },
      "source": [
        "%cd /home/\n",
        "!git clone https://github.com/NVIDIA/apex.git apex\n",
        "%cd apex\n",
        "!git checkout a651e2c24ecf97cbf367fd3f330df36760e1c597 ."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home\n",
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8038, done.\u001b[K\n",
            "remote: Counting objects: 100% (125/125), done.\u001b[K\n",
            "remote: Compressing objects: 100% (90/90), done.\u001b[K\n",
            "remote: Total 8038 (delta 58), reused 65 (delta 30), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8038/8038), 14.10 MiB | 28.71 MiB/s, done.\n",
            "Resolving deltas: 100% (5459/5459), done.\n",
            "/home/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaQ1O3axqviZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88e179b-3c0c-4c2e-86f3-c058c0e8b3f7"
      },
      "source": [
        "# install apex\n",
        "!python setup.py install --cuda_ext --cpp_ext"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "torch.__version__  = 1.8.1+cu101\n",
            "\n",
            "\n",
            "setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "  warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "Compiling cuda extensions with\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "from /usr/local/cuda/bin\n",
            "\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating apex.egg-info\n",
            "writing apex.egg-info/PKG-INFO\n",
            "writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "writing top-level names to apex.egg-info/top_level.txt\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/apex\n",
            "copying apex/__init__.py -> build/lib.linux-x86_64-3.7/apex\n",
            "creating build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "creating build/lib.linux-x86_64-3.7/apex/RNN\n",
            "copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "copying apex/RNN/models.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "creating build/lib.linux-x86_64-3.7/apex/normalization\n",
            "copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "creating build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/handle.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/opt.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/utils.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/amp.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "creating build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "creating build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "creating build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "creating build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "creating build/lib.linux-x86_64-3.7/apex/parallel\n",
            "copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib\n",
            "copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib\n",
            "creating build/lib.linux-x86_64-3.7/apex/mlp\n",
            "copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "creating build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "creating build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "creating build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "creating build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "creating build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "running build_ext\n",
            "building 'apex_C' extension\n",
            "creating /home/apex/build/temp.linux-x86_64-3.7\n",
            "creating /home/apex/build/temp.linux-x86_64-3.7/csrc\n",
            "Emitting ninja build file /home/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/1] c++ -MMD -MF /home/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /home/apex/csrc/flatten_unflatten.cpp -o /home/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/flatten_unflatten.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "In file included from /home/apex/csrc/flatten_unflatten.cpp:2:0:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:44:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     return tensors[0].type();\n",
            "                            ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/flatten_unflatten.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /home/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'amp_C' extension\n",
            "Emitting ninja build file /home/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_scale_kernel.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[2/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_sgd_kernel.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[3/11] c++ -MMD -MF /home/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/amp_C_frontend.cpp -o /home/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/amp_C_frontend.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "[4/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_lamb_stage_1.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[5/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_axpby_kernel.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[6/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_l2norm_kernel.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[7/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_adam.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[8/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_lamb_stage_2.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[9/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_adagrad.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[10/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_novograd.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[11/11] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/multi_tensor_lamb.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /home/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o /home/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'syncbn' extension\n",
            "Emitting ninja build file /home/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/2] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/welford.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[2/2] c++ -MMD -MF /home/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/syncbn.cpp -o /home/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/syncbn.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /home/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o /home/apex/build/temp.linux-x86_64-3.7/csrc/welford.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'fused_layer_norm_cuda' extension\n",
            "Emitting ninja build file /home/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/2] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/layer_norm_cuda_kernel.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "[2/2] c++ -MMD -MF /home/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/layer_norm_cuda.cpp -o /home/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(input);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:149:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(input);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(gamma);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(beta);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:193:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(dout);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:194:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(mean);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:195:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(invvar);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:196:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(input);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(dout);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(mean);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:220:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(invvar);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:221:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(input);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:222:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(gamma);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            " #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                 ^~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "   if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            " #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            " #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                        ^~~~~~~~~~\n",
            "/home/apex/csrc/layer_norm_cuda.cpp:223:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "   CHECK_INPUT(beta);\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /home/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o /home/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "building 'mlp_cuda' extension\n",
            "Emitting ninja build file /home/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/2] c++ -MMD -MF /home/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/mlp.cpp -o /home/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "/home/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "/home/apex/csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "   for (int i = 0; i < num_layers; i++) {\n",
            "                   ~~^~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                             ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "/home/apex/csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "/home/apex/csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "   auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                    ^\n",
            "/home/apex/csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/home/apex/csrc/mlp.cpp: In lambda function:\n",
            "/home/apex/csrc/mlp.cpp:67:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                      ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     const auto& the_type = TYPE;                                               \\\n",
            "                            ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                        ^\n",
            "/home/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "   ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp: In lambda function:\n",
            "/home/apex/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < num_layers; i++) {\n",
            "                     ~~^~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     auto result = mlp_fp<scalar_t>(\n",
            "          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp: In lambda function:\n",
            "/home/apex/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < num_layers; i++) {\n",
            "                     ~~^~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     auto result = mlp_fp<scalar_t>(\n",
            "          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp: In lambda function:\n",
            "/home/apex/csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < num_layers; i++) {\n",
            "                     ~~^~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     auto result = mlp_fp<scalar_t>(\n",
            "          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "/home/apex/csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "   for (int i = 0; i < num_layers; i++) {\n",
            "                   ~~^~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "   for (int i = 0; i < inputs.size(); i++) {\n",
            "                   ~~^~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:120:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/home/apex/csrc/mlp.cpp: In lambda function:\n",
            "/home/apex/csrc/mlp.cpp:123:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                      ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "     const auto& the_type = TYPE;                                               \\\n",
            "                            ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "     at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                        ^\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            " inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                       ^~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp: In lambda function:\n",
            "/home/apex/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < num_layers; i++) {\n",
            "                     ~~^~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < inputs.size(); i++) {\n",
            "                     ~~^~~~~~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/home/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                  ~~~~~~~~~~^~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                  ~~~~~~~~~~^~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     auto result = mlp_bp<scalar_t>(\n",
            "          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp: In lambda function:\n",
            "/home/apex/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < num_layers; i++) {\n",
            "                     ~~^~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < inputs.size(); i++) {\n",
            "                     ~~^~~~~~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/home/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                  ~~~~~~~~~~^~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                  ~~~~~~~~~~^~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     auto result = mlp_bp<scalar_t>(\n",
            "          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp: In lambda function:\n",
            "/home/apex/csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < num_layers; i++) {\n",
            "                     ~~^~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "     for (int i = 0; i < inputs.size(); i++) {\n",
            "                     ~~^~~~~~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:137:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "   DeprecatedTypeProperties & type() const {\n",
            "                              ^~~~\n",
            "In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                 from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                 from /home/apex/csrc/mlp.cpp:1:\n",
            "/home/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                  ~~~~~~~~~~^~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "     auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                  ~~~~~~~~~~^~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "/home/apex/csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "     auto result = mlp_bp<scalar_t>(\n",
            "          ^\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "     return __VA_ARGS__();                                                        \\\n",
            "            ^~~~~~~~~~~\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "       AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "       ^~~~~~~~~~~~~~~~~~~~\n",
            "/home/apex/csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "   ^\n",
            "[2/2] /usr/local/cuda/bin/nvcc  -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /home/apex/csrc/mlp_cuda.cu -o /home/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 -std=c++14\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-a56wZI/python3.7-3.7.10=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /home/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o /home/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/mlp_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/apex\n",
            "creating build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/fp16_utils\n",
            "creating build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.7/apex/RNN/cells.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.7/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.7/apex/RNN/__init__.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "copying build/lib.linux-x86_64-3.7/apex/RNN/models.py -> build/bdist.linux-x86_64/egg/apex/RNN\n",
            "creating build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib.linux-x86_64-3.7/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "copying build/lib.linux-x86_64-3.7/apex/normalization/__init__.py -> build/bdist.linux-x86_64/egg/apex/normalization\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/__version__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/frontend.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp/lists\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/handle.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/scaler.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/_initialize.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/opt.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/utils.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/wrap.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/amp.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "copying build/lib.linux-x86_64-3.7/apex/amp/__init__.py -> build/bdist.linux-x86_64/egg/apex/amp\n",
            "creating build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.7/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.7/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "copying build/lib.linux-x86_64-3.7/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/egg/apex/reparameterization\n",
            "creating build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/egg/apex/pyprof/prof\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/parse\n",
            "creating build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof/nvtx\n",
            "copying build/lib.linux-x86_64-3.7/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/egg/apex/pyprof\n",
            "creating build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib.linux-x86_64-3.7/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "copying build/lib.linux-x86_64-3.7/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/egg/apex/multi_tensor_apply\n",
            "creating build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.7/apex/parallel/distributed.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.7/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.7/apex/parallel/LARC.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.7/apex/parallel/__init__.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/egg/apex/parallel\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/fmha\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/groupbn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/sparsity\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/xentropy\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/transducer\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/egg/apex/contrib/optimizers\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/layer_norm\n",
            "creating build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib/bottleneck\n",
            "copying build/lib.linux-x86_64-3.7/apex/contrib/__init__.py -> build/bdist.linux-x86_64/egg/apex/contrib\n",
            "creating build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib.linux-x86_64-3.7/apex/mlp/mlp.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib.linux-x86_64-3.7/apex/mlp/__init__.py -> build/bdist.linux-x86_64/egg/apex/mlp\n",
            "copying build/lib.linux-x86_64-3.7/apex/__init__.py -> build/bdist.linux-x86_64/egg/apex\n",
            "copying build/lib.linux-x86_64-3.7/mlp_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16util.py to fp16util.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/cells.py to cells.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/RNNBackend.py to RNNBackend.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/RNN/models.py to models.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/normalization/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__version__.py to __version__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/frontend.py to frontend.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/lists/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/handle.py to handle.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_process_optimizer.py to _process_optimizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_amp_state.py to _amp_state.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/scaler.py to scaler.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/_initialize.py to _initialize.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/opt.py to opt.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/wrap.py to wrap.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/compat.py to compat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/rnn_compat.py to rnn_compat.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/amp.py to amp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/amp/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/weight_norm.py to weight_norm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/reparameterization.py to reparameterization.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/reparameterization/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/fused_novograd.py to fused_novograd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/optimizers/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pooling.py to pooling.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/base.py to base.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/activation.py to activation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__main__.py to __main__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/misc.py to misc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/data.py to data.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/reduction.py to reduction.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/prof.py to prof.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/output.py to output.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/conv.py to conv.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/convert.py to convert.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/dropout.py to dropout.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/optim.py to optim.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/embedding.py to embedding.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/linear.py to linear.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/usage.py to usage.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/randomSample.py to randomSample.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/normalization.py to normalization.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/blas.py to blas.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/utility.py to utility.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/pointwise.py to pointwise.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/softmax.py to softmax.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/prof/loss.py to loss.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/db.py to db.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__main__.py to __main__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/parse.py to parse.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/kernel.py to kernel.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/nvvp.py to nvvp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/parse/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/nvtx/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/pyprof/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/multi_tensor_apply/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/distributed.py to distributed.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/multiproc.py to multiproc.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/LARC.py to LARC.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/fmha.py to fmha.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/fmha/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/groupbn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/asp.py to asp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/sparsity/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/xentropy/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/transducer.py to transducer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/transducer/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/layer_norm/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/test.py to test.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/bottleneck/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/contrib/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/mlp.py to mlp.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/mlp/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex/__init__.py to __init__.cpython-37.pyc\n",
            "creating stub loader for apex_C.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for amp_C.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for syncbn.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "creating stub loader for mlp_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/apex_C.py to apex_C.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/amp_C.py to amp_C.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/syncbn.py to syncbn.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/fused_layer_norm_cuda.py to fused_layer_norm_cuda.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mlp_cuda.py to mlp_cuda.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying apex.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.amp_C.cpython-37: module references __file__\n",
            "__pycache__.apex_C.cpython-37: module references __file__\n",
            "__pycache__.fused_layer_norm_cuda.cpython-37: module references __file__\n",
            "__pycache__.mlp_cuda.cpython-37: module references __file__\n",
            "__pycache__.syncbn.cpython-37: module references __file__\n",
            "apex.pyprof.nvtx.__pycache__.nvmarker.cpython-37: module references __file__\n",
            "apex.pyprof.nvtx.__pycache__.nvmarker.cpython-37: module references __path__\n",
            "creating dist\n",
            "creating 'dist/apex-0.1-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing apex-0.1-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7-linux-x86_64.egg\n",
            "Extracting apex-0.1-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding apex 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for apex==0.1\n",
            "Finished processing dependencies for apex==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdmZ6zuJqpof",
        "outputId": "b9931cfb-439b-469c-82e6-8028ea2d9ad1"
      },
      "source": [
        "%cd ~\n",
        "!pip install git+https://github.com/zhanghang1989/PyTorch-Encoding/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "Collecting git+https://github.com/zhanghang1989/PyTorch-Encoding/\n",
            "  Cloning https://github.com/zhanghang1989/PyTorch-Encoding/ to /tmp/pip-req-build-utdc140f\n",
            "  Running command git clone -q https://github.com/zhanghang1989/PyTorch-Encoding/ /tmp/pip-req-build-utdc140f\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210420) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210420) (4.41.1)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210420) (1.3.7)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210420) (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210420) (0.9.1+cu101)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210420) (7.1.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210420) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210420) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->torch-encoding==1.2.2b20210420) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210420) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210420) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210420) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210420) (2.10)\n",
            "Building wheels for collected packages: torch-encoding\n",
            "  Building wheel for torch-encoding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-encoding: filename=torch_encoding-1.2.2b20210420-cp37-cp37m-linux_x86_64.whl size=8227853 sha256=ff90a62558eb3950c9ed232cdeae4254ec2e82104479221b4492208bebf1a014\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t3dxml23/wheels/f8/4f/46/924a4c89ee95252b34c3e257f1de2664a053e52c5aa5013d4a\n",
            "Successfully built torch-encoding\n",
            "Installing collected packages: portalocker, torch-encoding\n",
            "Successfully installed portalocker-2.3.0 torch-encoding-1.2.2b20210420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI_dVe5PYxF4"
      },
      "source": [
        "### 1.5. Config Setup\n",
        " - Inside `CSC413FinalProject/HMSA/config.py`, set the following items:\n",
        "  ```\n",
        "  __C.ASSETS_PATH = '/content/drive/MyDrive/data'\n",
        "  __C.DATASET.CITYSCAPES_DIR = \\\n",
        "  os.path.join(__C.ASSETS_PATH, 'citys')\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exM6E2jzariZ"
      },
      "source": [
        "* Copy the most recent snapshot weights into `/content/drive/MyDrive/data/seg_weights/`\n",
        "\n",
        "* Since Colab only has one GPU, we need to adjust the evaluation script\n",
        "\n",
        "* Inside `CSC413FinalProject/HMSA/scripts/train_cityscapes_deepv3.yml`, set the following:\n",
        "  ```\n",
        "  CMD: \"python -m torch.distributed.launch --nproc_per_node=1 train.py\"\n",
        "  bs_trn: 32\n",
        "  arch: mscale.DeepV3RN50,\n",
        "  snapshot: \"ASSETS_PATH/seg_weights/<weight-file-name>.pth\",\n",
        "\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5O_Vl0-ZXxh"
      },
      "source": [
        "## 2. Training on Cityscapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrPt4xOZrjH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da93d4d4-77da-4bc1-c130-88657e9deccd"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=3aced381f783065a949bd1875adf8af45800bf5c05f619ba9f1d3d16e369588b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  |     Proc size: 120.2 MB\n",
            "GPU RAM Free: 15109MB | Used: 0MB | Util   0% | Total     15109MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVQNGyX0hM-l",
        "outputId": "6459f55b-710d-4b5a-de95-c9cc29f31815"
      },
      "source": [
        "%cd /content/drive/MyDrive/CSC413/CSC413FinalProject/HMSA_ResNest/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CSC413/CSC413FinalProject/HMSA_ResNest\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4K1Z8MhZls1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f79de3-23a7-48df-ddb5-9a9cfb0d8eed"
      },
      "source": [
        "# dry run (to see full command)\n",
        "!python -m runx.runx scripts/train_cityscapes.yml -i -n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python -m torch.distributed.launch --nproc_per_node=1 train.py --dataset cityscapes --cv 0 --syncbn --apex --fp16 --crop_size 300,600 --bs_trn 8 --poly_exp 2 --lr 0.003067 --rmi_loss --max_epoch 100 --n_scales 0.5,1.0,2.0 --supervised_mscale_loss_wt 0.05 --snapshot ASSETS_PATH/seg_weights/HMSA_ResNest_resolute-axolotl_ep4.pth --arch mscale.DeepV3RN50 --result_dir logs/train_cityscapes/mscale.DeepV3RN50_tall-dormouse_2021.04.20_00.36 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eISfNUO9ZsPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57c728c-829d-4f91-d30e-a5f010d0f5a9"
      },
      "source": [
        "# real run\n",
        "!python -m runx.runx scripts/train_cityscapes.yml -i"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "Global Rank: 0 Local Rank: 0\n",
            "Torch version: 1.8, 1.8.1+cu101\n",
            "n scales [0.5, 1.0, 2.0]\n",
            "dataset = cityscapes\n",
            "ignore_label = 255\n",
            "num_classes = 19\n",
            "cv split val 0 ['val/frankfurt', 'val/lindau', 'val/munster']\n",
            "mode val found 500 images\n",
            "cn num_classes 19\n",
            "cv split train 0 ['train/aachen', 'train/bochum', 'train/bremen', 'train/cologne', 'train/darmstadt', 'train/dusseldorf', 'train/erfurt', 'train/hamburg', 'train/hanover', 'train/jena', 'train/krefeld', 'train/monchengladbach', 'train/strasbourg', 'train/stuttgart', 'train/tubingen', 'train/ulm', 'train/weimar', 'train/zurich']\n",
            "mode train found 2975 images\n",
            "cn num_classes 19\n",
            "Loading centroid file /content/drive/MyDrive/data/uniform_centroids/cityscapes_cv0_tile1024.json\n",
            "Found 19 centroids\n",
            "Class Uniform Percentage: 0.5\n",
            "Class Uniform items per Epoch: 2975\n",
            "cls 0 len 5866\n",
            "cls 1 len 5184\n",
            "cls 2 len 5678\n",
            "cls 3 len 1312\n",
            "cls 4 len 1723\n",
            "cls 5 len 5656\n",
            "cls 6 len 2769\n",
            "cls 7 len 4860\n",
            "cls 8 len 5388\n",
            "cls 9 len 2440\n",
            "cls 10 len 4722\n",
            "cls 11 len 3719\n",
            "cls 12 len 1239\n",
            "cls 13 len 5075\n",
            "cls 14 len 444\n",
            "cls 15 len 348\n",
            "cls 16 len 188\n",
            "cls 17 len 575\n",
            "cls 18 len 2238\n",
            "Using Cross Entropy Loss\n",
            "Loading weights from: checkpoint=/content/drive/MyDrive/data/seg_weights/HMSA_ResNest_resolute-axolotl_ep4.pth\n",
            "Trunk: resnest-50\n",
            "Model params = 43.6M\n",
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Class Uniform Percentage: 0.5\n",
            "Class Uniform items per Epoch: 2975\n",
            "cls 0 len 5866\n",
            "cls 1 len 5184\n",
            "cls 2 len 5678\n",
            "cls 3 len 1312\n",
            "cls 4 len 1723\n",
            "cls 5 len 5656\n",
            "cls 6 len 2769\n",
            "cls 7 len 4860\n",
            "cls 8 len 5388\n",
            "cls 9 len 2440\n",
            "cls 10 len 4722\n",
            "cls 11 len 3719\n",
            "cls 12 len 1239\n",
            "cls 13 len 5075\n",
            "cls 14 len 444\n",
            "cls 15 len 348\n",
            "cls 16 len 188\n",
            "cls 17 len 575\n",
            "cls 18 len 2238\n",
            "[epoch 0], [iter 1 / 495], [train main loss -16.109280], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 2 / 495], [train main loss -18.560966], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 3 / 495], [train main loss -15.868001], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 4 / 495], [train main loss -17.726417], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 5 / 495], [train main loss -18.158064], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 6 / 495], [train main loss -19.396102], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 7 / 495], [train main loss -18.458788], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 8 / 495], [train main loss -16.770940], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 9 / 495], [train main loss -16.974031], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 10 / 495], [train main loss -16.586504], [lr 0.003067] [batchtime 0]\n",
            "[epoch 0], [iter 11 / 495], [train main loss -16.961542], [lr 0.003067] [batchtime 2.7]\n",
            "[epoch 0], [iter 12 / 495], [train main loss -17.602043], [lr 0.003067] [batchtime 2.71]\n",
            "[epoch 0], [iter 13 / 495], [train main loss -16.964030], [lr 0.003067] [batchtime 2.72]\n",
            "[epoch 0], [iter 14 / 495], [train main loss -17.237399], [lr 0.003067] [batchtime 2.72]\n",
            "[epoch 0], [iter 15 / 495], [train main loss -17.242570], [lr 0.003067] [batchtime 2.73]\n",
            "[epoch 0], [iter 16 / 495], [train main loss -16.745228], [lr 0.003067] [batchtime 2.73]\n",
            "[epoch 0], [iter 17 / 495], [train main loss -16.751780], [lr 0.003067] [batchtime 2.74]\n",
            "[epoch 0], [iter 18 / 495], [train main loss -17.042376], [lr 0.003067] [batchtime 2.74]\n",
            "[epoch 0], [iter 19 / 495], [train main loss -17.101600], [lr 0.003067] [batchtime 2.74]\n",
            "[epoch 0], [iter 20 / 495], [train main loss -16.876483], [lr 0.003067] [batchtime 2.75]\n",
            "[epoch 0], [iter 21 / 495], [train main loss -16.771294], [lr 0.003067] [batchtime 2.75]\n",
            "[epoch 0], [iter 22 / 495], [train main loss -16.723230], [lr 0.003067] [batchtime 2.75]\n",
            "[epoch 0], [iter 23 / 495], [train main loss -16.774011], [lr 0.003067] [batchtime 2.75]\n",
            "[epoch 0], [iter 24 / 495], [train main loss -17.097556], [lr 0.003067] [batchtime 2.75]\n",
            "[epoch 0], [iter 25 / 495], [train main loss -16.972382], [lr 0.003067] [batchtime 2.76]\n",
            "[epoch 0], [iter 26 / 495], [train main loss -16.771767], [lr 0.003067] [batchtime 2.76]\n",
            "[epoch 0], [iter 27 / 495], [train main loss -16.875394], [lr 0.003067] [batchtime 2.77]\n",
            "[epoch 0], [iter 28 / 495], [train main loss -16.936247], [lr 0.003067] [batchtime 2.77]\n",
            "[epoch 0], [iter 29 / 495], [train main loss -16.912856], [lr 0.003067] [batchtime 2.77]\n",
            "[epoch 0], [iter 30 / 495], [train main loss -16.844847], [lr 0.003067] [batchtime 2.77]\n",
            "[epoch 0], [iter 31 / 495], [train main loss -16.655720], [lr 0.003067] [batchtime 2.77]\n",
            "[epoch 0], [iter 32 / 495], [train main loss -16.570497], [lr 0.003067] [batchtime 2.77]\n",
            "[epoch 0], [iter 33 / 495], [train main loss -16.277992], [lr 0.003067] [batchtime 2.78]\n",
            "[epoch 0], [iter 34 / 495], [train main loss -16.436893], [lr 0.003067] [batchtime 2.78]\n",
            "[epoch 0], [iter 35 / 495], [train main loss -16.435176], [lr 0.003067] [batchtime 2.78]\n",
            "[epoch 0], [iter 36 / 495], [train main loss -16.383264], [lr 0.003067] [batchtime 2.78]\n",
            "[epoch 0], [iter 37 / 495], [train main loss -16.508518], [lr 0.003067] [batchtime 2.79]\n",
            "[epoch 0], [iter 38 / 495], [train main loss -16.428873], [lr 0.003067] [batchtime 2.79]\n",
            "[epoch 0], [iter 39 / 495], [train main loss -16.366789], [lr 0.003067] [batchtime 2.79]\n",
            "[epoch 0], [iter 40 / 495], [train main loss -16.466418], [lr 0.003067] [batchtime 2.79]\n",
            "[epoch 0], [iter 41 / 495], [train main loss -16.238554], [lr 0.003067] [batchtime 2.8]\n",
            "[epoch 0], [iter 42 / 495], [train main loss -16.142302], [lr 0.003067] [batchtime 2.8]\n",
            "[epoch 0], [iter 43 / 495], [train main loss -16.184933], [lr 0.003067] [batchtime 2.8]\n",
            "[epoch 0], [iter 44 / 495], [train main loss -16.223405], [lr 0.003067] [batchtime 2.8]\n",
            "[epoch 0], [iter 45 / 495], [train main loss -16.237216], [lr 0.003067] [batchtime 2.81]\n",
            "[epoch 0], [iter 46 / 495], [train main loss -16.246994], [lr 0.003067] [batchtime 2.81]\n",
            "[epoch 0], [iter 47 / 495], [train main loss -16.269032], [lr 0.003067] [batchtime 2.81]\n",
            "[epoch 0], [iter 48 / 495], [train main loss -16.260454], [lr 0.003067] [batchtime 2.81]\n",
            "[epoch 0], [iter 49 / 495], [train main loss -16.231395], [lr 0.003067] [batchtime 2.81]\n",
            "[epoch 0], [iter 50 / 495], [train main loss -16.223253], [lr 0.003067] [batchtime 2.82]\n",
            "[epoch 0], [iter 51 / 495], [train main loss -16.058809], [lr 0.003067] [batchtime 2.82]\n",
            "[epoch 0], [iter 52 / 495], [train main loss -16.210706], [lr 0.003067] [batchtime 2.82]\n",
            "[epoch 0], [iter 53 / 495], [train main loss -16.138623], [lr 0.003067] [batchtime 2.82]\n",
            "[epoch 0], [iter 54 / 495], [train main loss -16.110443], [lr 0.003067] [batchtime 2.82]\n",
            "[epoch 0], [iter 55 / 495], [train main loss -16.042366], [lr 0.003067] [batchtime 2.83]\n",
            "[epoch 0], [iter 56 / 495], [train main loss -15.924589], [lr 0.003067] [batchtime 2.83]\n",
            "[epoch 0], [iter 57 / 495], [train main loss -15.905783], [lr 0.003067] [batchtime 2.83]\n",
            "[epoch 0], [iter 58 / 495], [train main loss -15.857273], [lr 0.003067] [batchtime 2.83]\n",
            "[epoch 0], [iter 59 / 495], [train main loss -15.756296], [lr 0.003067] [batchtime 2.84]\n",
            "[epoch 0], [iter 60 / 495], [train main loss -15.828221], [lr 0.003067] [batchtime 2.84]\n",
            "[epoch 0], [iter 61 / 495], [train main loss -15.800634], [lr 0.003067] [batchtime 2.84]\n",
            "[epoch 0], [iter 62 / 495], [train main loss -15.862716], [lr 0.003067] [batchtime 2.84]\n",
            "[epoch 0], [iter 63 / 495], [train main loss -15.833187], [lr 0.003067] [batchtime 2.84]\n",
            "[epoch 0], [iter 64 / 495], [train main loss -15.804604], [lr 0.003067] [batchtime 2.84]\n",
            "[epoch 0], [iter 65 / 495], [train main loss -15.796029], [lr 0.003067] [batchtime 2.85]\n",
            "[epoch 0], [iter 66 / 495], [train main loss -15.676705], [lr 0.003067] [batchtime 2.85]\n",
            "[epoch 0], [iter 67 / 495], [train main loss -15.647552], [lr 0.003067] [batchtime 2.85]\n",
            "[epoch 0], [iter 68 / 495], [train main loss -15.643840], [lr 0.003067] [batchtime 2.85]\n",
            "[epoch 0], [iter 69 / 495], [train main loss -15.705317], [lr 0.003067] [batchtime 2.85]\n",
            "[epoch 0], [iter 70 / 495], [train main loss -15.702183], [lr 0.003067] [batchtime 2.85]\n",
            "[epoch 0], [iter 71 / 495], [train main loss -15.662010], [lr 0.003067] [batchtime 2.86]\n",
            "[epoch 0], [iter 72 / 495], [train main loss -15.642064], [lr 0.003067] [batchtime 2.86]\n",
            "[epoch 0], [iter 73 / 495], [train main loss -15.583107], [lr 0.003067] [batchtime 2.86]\n",
            "[epoch 0], [iter 74 / 495], [train main loss -15.511385], [lr 0.003067] [batchtime 2.86]\n",
            "[epoch 0], [iter 75 / 495], [train main loss -15.499709], [lr 0.003067] [batchtime 2.86]\n",
            "[epoch 0], [iter 76 / 495], [train main loss -15.473371], [lr 0.003067] [batchtime 2.86]\n",
            "[epoch 0], [iter 77 / 495], [train main loss -15.460116], [lr 0.003067] [batchtime 2.86]\n",
            "[epoch 0], [iter 78 / 495], [train main loss -15.542526], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 79 / 495], [train main loss -15.529261], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 80 / 495], [train main loss -15.480653], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 81 / 495], [train main loss -15.517743], [lr 0.003067] [batchtime 2.87]\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "[epoch 0], [iter 82 / 495], [train main loss -15.528102], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 83 / 495], [train main loss -15.575417], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 84 / 495], [train main loss -15.539429], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 85 / 495], [train main loss -15.499199], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 86 / 495], [train main loss -15.501106], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 87 / 495], [train main loss -15.419676], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 88 / 495], [train main loss -15.443345], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 89 / 495], [train main loss -15.420000], [lr 0.003067] [batchtime 2.87]\n",
            "[epoch 0], [iter 90 / 495], [train main loss -15.425166], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 91 / 495], [train main loss -15.393636], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 92 / 495], [train main loss -15.408758], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 93 / 495], [train main loss -15.373977], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 94 / 495], [train main loss -15.391145], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 95 / 495], [train main loss -15.452917], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 96 / 495], [train main loss -15.481689], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 97 / 495], [train main loss -15.418640], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 98 / 495], [train main loss -15.412338], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 99 / 495], [train main loss -15.397199], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 100 / 495], [train main loss -15.436866], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 101 / 495], [train main loss -15.355002], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 102 / 495], [train main loss -15.315820], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 103 / 495], [train main loss -15.357531], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 104 / 495], [train main loss -15.399308], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 105 / 495], [train main loss -15.415964], [lr 0.003067] [batchtime 2.88]\n",
            "[epoch 0], [iter 106 / 495], [train main loss -15.432789], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 107 / 495], [train main loss -15.499592], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 108 / 495], [train main loss -15.544695], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 109 / 495], [train main loss -15.534371], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 110 / 495], [train main loss -15.480757], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 111 / 495], [train main loss -15.466194], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 112 / 495], [train main loss -15.425828], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 113 / 495], [train main loss -15.437116], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 114 / 495], [train main loss -15.420340], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 115 / 495], [train main loss -15.436565], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 116 / 495], [train main loss -15.471106], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 117 / 495], [train main loss -15.469060], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 118 / 495], [train main loss -15.495676], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 119 / 495], [train main loss -15.484492], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 120 / 495], [train main loss -15.564433], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 121 / 495], [train main loss -15.587019], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 122 / 495], [train main loss -15.580585], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 123 / 495], [train main loss -15.578591], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 124 / 495], [train main loss -15.561760], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 125 / 495], [train main loss -15.578201], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 126 / 495], [train main loss -15.591241], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 127 / 495], [train main loss -15.573559], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 128 / 495], [train main loss -15.631341], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 129 / 495], [train main loss -15.628402], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 130 / 495], [train main loss -15.628432], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 131 / 495], [train main loss -15.588230], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 132 / 495], [train main loss -15.602962], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 133 / 495], [train main loss -15.624252], [lr 0.003067] [batchtime 2.89]\n",
            "[epoch 0], [iter 134 / 495], [train main loss -15.622539], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 135 / 495], [train main loss -15.648808], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 136 / 495], [train main loss -15.644600], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 137 / 495], [train main loss -15.681221], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 138 / 495], [train main loss -15.699498], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 139 / 495], [train main loss -15.658294], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 140 / 495], [train main loss -15.653402], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 141 / 495], [train main loss -15.662519], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 142 / 495], [train main loss -15.679253], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 143 / 495], [train main loss -15.713042], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 144 / 495], [train main loss -15.698782], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 145 / 495], [train main loss -15.689363], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 146 / 495], [train main loss -15.738418], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 147 / 495], [train main loss -15.702841], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 148 / 495], [train main loss -15.683399], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 149 / 495], [train main loss -15.717153], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 150 / 495], [train main loss -15.727436], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 151 / 495], [train main loss -15.767143], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 152 / 495], [train main loss -15.769465], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 153 / 495], [train main loss -15.774158], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 154 / 495], [train main loss -15.748874], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 155 / 495], [train main loss -15.692057], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 156 / 495], [train main loss -15.691270], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 157 / 495], [train main loss -15.700068], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 158 / 495], [train main loss -15.698002], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 159 / 495], [train main loss -15.675160], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 160 / 495], [train main loss -15.622125], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 161 / 495], [train main loss -15.608399], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 162 / 495], [train main loss -15.621249], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 163 / 495], [train main loss -15.592836], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 164 / 495], [train main loss -15.633852], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 165 / 495], [train main loss -15.620392], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 166 / 495], [train main loss -15.693153], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 167 / 495], [train main loss -15.712341], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 168 / 495], [train main loss -15.723341], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 169 / 495], [train main loss -15.686579], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 170 / 495], [train main loss -15.677816], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 171 / 495], [train main loss -15.666044], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 172 / 495], [train main loss -15.663989], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 173 / 495], [train main loss -15.671061], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 174 / 495], [train main loss -15.671702], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 175 / 495], [train main loss -15.666383], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 176 / 495], [train main loss -15.646149], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 177 / 495], [train main loss -15.642257], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 178 / 495], [train main loss -15.653151], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 179 / 495], [train main loss -15.677475], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 180 / 495], [train main loss -15.672231], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 181 / 495], [train main loss -15.646323], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 182 / 495], [train main loss -15.639011], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 183 / 495], [train main loss -15.608248], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 184 / 495], [train main loss -15.635631], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 185 / 495], [train main loss -15.640029], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 186 / 495], [train main loss -15.594486], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 187 / 495], [train main loss -15.564812], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 188 / 495], [train main loss -15.558231], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 189 / 495], [train main loss -15.540623], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 190 / 495], [train main loss -15.553532], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 191 / 495], [train main loss -15.528508], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 192 / 495], [train main loss -15.530230], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 193 / 495], [train main loss -15.508837], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 194 / 495], [train main loss -15.523172], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 195 / 495], [train main loss -15.529818], [lr 0.003067] [batchtime 2.9]\n",
            "[epoch 0], [iter 196 / 495], [train main loss -15.511832], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 197 / 495], [train main loss -15.518794], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 198 / 495], [train main loss -15.530021], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 199 / 495], [train main loss -15.544457], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 200 / 495], [train main loss -15.527748], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 201 / 495], [train main loss -15.506999], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 202 / 495], [train main loss -15.491862], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 203 / 495], [train main loss -15.473860], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 204 / 495], [train main loss -15.462225], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 205 / 495], [train main loss -15.483162], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 206 / 495], [train main loss -15.468305], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 207 / 495], [train main loss -15.473292], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 208 / 495], [train main loss -15.460395], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 209 / 495], [train main loss -15.461219], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 210 / 495], [train main loss -15.452930], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 211 / 495], [train main loss -15.456725], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 212 / 495], [train main loss -15.460138], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 213 / 495], [train main loss -15.454694], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 214 / 495], [train main loss -15.481730], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 215 / 495], [train main loss -15.503546], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 216 / 495], [train main loss -15.466763], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 217 / 495], [train main loss -15.474006], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 218 / 495], [train main loss -15.506972], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 219 / 495], [train main loss -15.498757], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 220 / 495], [train main loss -15.508407], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 221 / 495], [train main loss -15.521694], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 222 / 495], [train main loss -15.507917], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 223 / 495], [train main loss -15.517674], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 224 / 495], [train main loss -15.528455], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 225 / 495], [train main loss -15.522824], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 226 / 495], [train main loss -15.494282], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 227 / 495], [train main loss -15.497099], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 228 / 495], [train main loss -15.512712], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 229 / 495], [train main loss -15.524626], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 230 / 495], [train main loss -15.522484], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 231 / 495], [train main loss -15.546109], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 232 / 495], [train main loss -15.533934], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 233 / 495], [train main loss -15.552134], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 234 / 495], [train main loss -15.535900], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 235 / 495], [train main loss -15.549851], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 236 / 495], [train main loss -15.567814], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 237 / 495], [train main loss -15.604253], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 238 / 495], [train main loss -15.592581], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 239 / 495], [train main loss -15.557630], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 240 / 495], [train main loss -15.571298], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 241 / 495], [train main loss -15.546306], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 242 / 495], [train main loss -15.545365], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 243 / 495], [train main loss -15.546662], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 244 / 495], [train main loss -15.527272], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 245 / 495], [train main loss -15.505507], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 246 / 495], [train main loss -15.514336], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 247 / 495], [train main loss -15.506648], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 248 / 495], [train main loss -15.528698], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 249 / 495], [train main loss -15.530748], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 250 / 495], [train main loss -15.519413], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 251 / 495], [train main loss -15.519242], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 252 / 495], [train main loss -15.546415], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 253 / 495], [train main loss -15.518965], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 254 / 495], [train main loss -15.515665], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 255 / 495], [train main loss -15.547312], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 256 / 495], [train main loss -15.550051], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 257 / 495], [train main loss -15.533548], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 258 / 495], [train main loss -15.532753], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 259 / 495], [train main loss -15.533977], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 260 / 495], [train main loss -15.497189], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 261 / 495], [train main loss -15.473456], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 262 / 495], [train main loss -15.465101], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 263 / 495], [train main loss -15.464575], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 264 / 495], [train main loss -15.481038], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 265 / 495], [train main loss -15.472559], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 266 / 495], [train main loss -15.472875], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 267 / 495], [train main loss -15.482949], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 268 / 495], [train main loss -15.453067], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 269 / 495], [train main loss -15.428556], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 270 / 495], [train main loss -15.419789], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 271 / 495], [train main loss -15.434120], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 272 / 495], [train main loss -15.431345], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 273 / 495], [train main loss -15.414008], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 274 / 495], [train main loss -15.442542], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 275 / 495], [train main loss -15.461445], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 276 / 495], [train main loss -15.458802], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 277 / 495], [train main loss -15.460445], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 278 / 495], [train main loss -15.477774], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 279 / 495], [train main loss -15.495314], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 280 / 495], [train main loss -15.491298], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 281 / 495], [train main loss -15.508903], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 282 / 495], [train main loss -15.516143], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 283 / 495], [train main loss -15.496372], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 284 / 495], [train main loss -15.511876], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 285 / 495], [train main loss -15.508515], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 286 / 495], [train main loss -15.516154], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 287 / 495], [train main loss -15.518854], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 288 / 495], [train main loss -15.520950], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 289 / 495], [train main loss -15.519855], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 290 / 495], [train main loss -15.508548], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 291 / 495], [train main loss -15.515660], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 292 / 495], [train main loss -15.521311], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 293 / 495], [train main loss -15.505423], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 294 / 495], [train main loss -15.494514], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 295 / 495], [train main loss -15.489881], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 296 / 495], [train main loss -15.469584], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 297 / 495], [train main loss -15.474659], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 298 / 495], [train main loss -15.476792], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 299 / 495], [train main loss -15.485905], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 300 / 495], [train main loss -15.489465], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 301 / 495], [train main loss -15.483367], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 302 / 495], [train main loss -15.488316], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 303 / 495], [train main loss -15.484896], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 304 / 495], [train main loss -15.465554], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 305 / 495], [train main loss -15.461047], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 306 / 495], [train main loss -15.467935], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 307 / 495], [train main loss -15.497975], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 308 / 495], [train main loss -15.515492], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 309 / 495], [train main loss -15.530229], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 310 / 495], [train main loss -15.548614], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 311 / 495], [train main loss -15.545353], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 312 / 495], [train main loss -15.538751], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 313 / 495], [train main loss -15.516672], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 314 / 495], [train main loss -15.496657], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 315 / 495], [train main loss -15.502282], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 316 / 495], [train main loss -15.478058], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 317 / 495], [train main loss -15.495307], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 318 / 495], [train main loss -15.523216], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 319 / 495], [train main loss -15.523958], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 320 / 495], [train main loss -15.519561], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 321 / 495], [train main loss -15.514962], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 322 / 495], [train main loss -15.526963], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 323 / 495], [train main loss -15.525202], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 324 / 495], [train main loss -15.529047], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 325 / 495], [train main loss -15.527167], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 326 / 495], [train main loss -15.529539], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 327 / 495], [train main loss -15.519578], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 328 / 495], [train main loss -15.503868], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 329 / 495], [train main loss -15.496436], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 330 / 495], [train main loss -15.488312], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 331 / 495], [train main loss -15.466830], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 332 / 495], [train main loss -15.479518], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 333 / 495], [train main loss -15.498758], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 334 / 495], [train main loss -15.487988], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 335 / 495], [train main loss -15.505965], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 336 / 495], [train main loss -15.500342], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 337 / 495], [train main loss -15.502894], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 338 / 495], [train main loss -15.527672], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 339 / 495], [train main loss -15.546676], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 340 / 495], [train main loss -15.537812], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 341 / 495], [train main loss -15.557509], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 342 / 495], [train main loss -15.547340], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 343 / 495], [train main loss -15.537325], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 344 / 495], [train main loss -15.532728], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 345 / 495], [train main loss -15.531602], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 346 / 495], [train main loss -15.535407], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 347 / 495], [train main loss -15.533253], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 348 / 495], [train main loss -15.522250], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 349 / 495], [train main loss -15.519728], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 350 / 495], [train main loss -15.516230], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 351 / 495], [train main loss -15.520236], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 352 / 495], [train main loss -15.515872], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 353 / 495], [train main loss -15.531414], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 354 / 495], [train main loss -15.530946], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 355 / 495], [train main loss -15.526855], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 356 / 495], [train main loss -15.541368], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 357 / 495], [train main loss -15.539902], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 358 / 495], [train main loss -15.567712], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 359 / 495], [train main loss -15.547324], [lr 0.003067] [batchtime 2.91]\n",
            "[epoch 0], [iter 360 / 495], [train main loss -15.559684], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 361 / 495], [train main loss -15.564953], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 362 / 495], [train main loss -15.556442], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 363 / 495], [train main loss -15.557396], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 364 / 495], [train main loss -15.546050], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 365 / 495], [train main loss -15.549055], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 366 / 495], [train main loss -15.568882], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 367 / 495], [train main loss -15.562321], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 368 / 495], [train main loss -15.562451], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 369 / 495], [train main loss -15.548991], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 370 / 495], [train main loss -15.547240], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 371 / 495], [train main loss -15.545386], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 372 / 495], [train main loss -15.542705], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 373 / 495], [train main loss -15.537685], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 374 / 495], [train main loss -15.550573], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 375 / 495], [train main loss -15.546095], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 376 / 495], [train main loss -15.539013], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 377 / 495], [train main loss -15.541444], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 378 / 495], [train main loss -15.544049], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 379 / 495], [train main loss -15.549449], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 380 / 495], [train main loss -15.549676], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 381 / 495], [train main loss -15.539293], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 382 / 495], [train main loss -15.521279], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 383 / 495], [train main loss -15.512750], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 384 / 495], [train main loss -15.510307], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 385 / 495], [train main loss -15.510457], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 386 / 495], [train main loss -15.524080], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 387 / 495], [train main loss -15.505975], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 388 / 495], [train main loss -15.496157], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 389 / 495], [train main loss -15.492297], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 390 / 495], [train main loss -15.493701], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 391 / 495], [train main loss -15.486110], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 392 / 495], [train main loss -15.500067], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 393 / 495], [train main loss -15.486884], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 394 / 495], [train main loss -15.489837], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 395 / 495], [train main loss -15.489106], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 396 / 495], [train main loss -15.487173], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 397 / 495], [train main loss -15.484786], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 398 / 495], [train main loss -15.494179], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 399 / 495], [train main loss -15.490918], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 400 / 495], [train main loss -15.504226], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 401 / 495], [train main loss -15.490844], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 402 / 495], [train main loss -15.488372], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 403 / 495], [train main loss -15.486419], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 404 / 495], [train main loss -15.509294], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 405 / 495], [train main loss -15.522565], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 406 / 495], [train main loss -15.528982], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 407 / 495], [train main loss -15.520387], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 408 / 495], [train main loss -15.533010], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 409 / 495], [train main loss -15.534599], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 410 / 495], [train main loss -15.538785], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 411 / 495], [train main loss -15.539346], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 412 / 495], [train main loss -15.549357], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 413 / 495], [train main loss -15.542064], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 414 / 495], [train main loss -15.548896], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 415 / 495], [train main loss -15.542582], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 416 / 495], [train main loss -15.558048], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 417 / 495], [train main loss -15.554686], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 418 / 495], [train main loss -15.547717], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 419 / 495], [train main loss -15.555385], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 420 / 495], [train main loss -15.557219], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 421 / 495], [train main loss -15.560165], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 422 / 495], [train main loss -15.560004], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 423 / 495], [train main loss -15.557109], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 424 / 495], [train main loss -15.556626], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 425 / 495], [train main loss -15.542002], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 426 / 495], [train main loss -15.516623], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 427 / 495], [train main loss -15.544456], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 428 / 495], [train main loss -15.538446], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 429 / 495], [train main loss -15.541115], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 430 / 495], [train main loss -15.545098], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 431 / 495], [train main loss -15.542517], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 432 / 495], [train main loss -15.533842], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 433 / 495], [train main loss -15.547151], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 434 / 495], [train main loss -15.531381], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 435 / 495], [train main loss -15.530666], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 436 / 495], [train main loss -15.510514], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 437 / 495], [train main loss -15.508438], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 438 / 495], [train main loss -15.512617], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 439 / 495], [train main loss -15.523142], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 440 / 495], [train main loss -15.510552], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 441 / 495], [train main loss -15.512561], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 442 / 495], [train main loss -15.501751], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 443 / 495], [train main loss -15.492291], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 444 / 495], [train main loss -15.492813], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 445 / 495], [train main loss -15.491664], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 446 / 495], [train main loss -15.490193], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 447 / 495], [train main loss -15.486435], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 448 / 495], [train main loss -15.478715], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 449 / 495], [train main loss -15.466917], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 450 / 495], [train main loss -15.471391], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 451 / 495], [train main loss -15.474836], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 452 / 495], [train main loss -15.464724], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 453 / 495], [train main loss -15.444988], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 454 / 495], [train main loss -15.443252], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 455 / 495], [train main loss -15.462191], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 456 / 495], [train main loss -15.461875], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 457 / 495], [train main loss -15.464653], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 458 / 495], [train main loss -15.471769], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 459 / 495], [train main loss -15.479220], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 460 / 495], [train main loss -15.474151], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 461 / 495], [train main loss -15.475847], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 462 / 495], [train main loss -15.471006], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 463 / 495], [train main loss -15.478505], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 464 / 495], [train main loss -15.487136], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 465 / 495], [train main loss -15.469701], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 466 / 495], [train main loss -15.481645], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 467 / 495], [train main loss -15.495570], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 468 / 495], [train main loss -15.514607], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 469 / 495], [train main loss -15.525297], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 470 / 495], [train main loss -15.524474], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 471 / 495], [train main loss -15.532400], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 472 / 495], [train main loss -15.542742], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 473 / 495], [train main loss -15.536039], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 474 / 495], [train main loss -15.528610], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 475 / 495], [train main loss -15.519384], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 476 / 495], [train main loss -15.522581], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 477 / 495], [train main loss -15.525307], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 478 / 495], [train main loss -15.519810], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 479 / 495], [train main loss -15.542181], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 480 / 495], [train main loss -15.540584], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 481 / 495], [train main loss -15.519687], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 482 / 495], [train main loss -15.509170], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 483 / 495], [train main loss -15.512747], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 484 / 495], [train main loss -15.515648], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 485 / 495], [train main loss -15.520927], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 486 / 495], [train main loss -15.514115], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 487 / 495], [train main loss -15.520555], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 488 / 495], [train main loss -15.530554], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 489 / 495], [train main loss -15.531075], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 490 / 495], [train main loss -15.543196], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 491 / 495], [train main loss -15.536114], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 492 / 495], [train main loss -15.523452], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 493 / 495], [train main loss -15.533206], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 494 / 495], [train main loss -15.534500], [lr 0.003067] [batchtime 2.92]\n",
            "[epoch 0], [iter 495 / 495], [train main loss -15.520408], [lr 0.003067] [batchtime 2.92]\n",
            "validating[Iter: 1 / 500]\n",
            "validating[Iter: 21 / 500]\n",
            "validating[Iter: 41 / 500]\n",
            "validating[Iter: 61 / 500]\n",
            "validating[Iter: 81 / 500]\n",
            "validating[Iter: 101 / 500]\n",
            "validating[Iter: 121 / 500]\n",
            "validating[Iter: 141 / 500]\n",
            "validating[Iter: 161 / 500]\n",
            "validating[Iter: 181 / 500]\n",
            "validating[Iter: 201 / 500]\n",
            "validating[Iter: 221 / 500]\n",
            "validating[Iter: 241 / 500]\n",
            "validating[Iter: 261 / 500]\n",
            "validating[Iter: 281 / 500]\n",
            "validating[Iter: 301 / 500]\n",
            "validating[Iter: 321 / 500]\n",
            "validating[Iter: 341 / 500]\n",
            "validating[Iter: 361 / 500]\n",
            "validating[Iter: 381 / 500]\n",
            "validating[Iter: 401 / 500]\n",
            "validating[Iter: 421 / 500]\n",
            "validating[Iter: 441 / 500]\n",
            "validating[Iter: 461 / 500]\n",
            "validating[Iter: 481 / 500]\n",
            "IoU:\n",
            "  Id  label            iU_1.0     TP       FP    FN    Precision    Recall\n",
            "----  -------------  --------  -----  -------  ----  -----------  --------\n",
            "   0  road              91.53  37.27     0.01  0.08         0.99      0.92\n",
            "   1  sidewalk          53.79   3.26     0.66  0.20         0.60      0.83\n",
            "   2  building          78.36  19.26     0.14  0.14         0.88      0.88\n",
            "   3  wall               3.49   0.03    27.35  0.29         0.04      0.78\n",
            "   4  fence             17.58   0.16     4.23  0.46         0.19      0.69\n",
            "   5  pole              40.01   0.96     0.55  0.95         0.65      0.51\n",
            "   6  traffic light      6.91   0.01    12.94  0.52         0.07      0.66\n",
            "   7  traffic sign      12.67   0.09     6.16  0.73         0.14      0.58\n",
            "   8  vegetation        81.64  14.94     0.16  0.07         0.86      0.94\n",
            "   9  terrain           29.25   0.36     1.31  1.11         0.43      0.47\n",
            "  10  sky               82.03   3.28     0.02  0.20         0.98      0.84\n",
            "  11  person            34.84   0.97     0.33  1.54         0.75      0.39\n",
            "  12  rider              0.03   0.00  2934.51  3.20         0.00      0.24\n",
            "  13  car               72.44   6.16     0.06  0.32         0.94      0.76\n",
            "  14  truck              0.45   0.00   220.26  2.58         0.00      0.28\n",
            "  15  bus                6.01   0.02    14.95  0.69         0.06      0.59\n",
            "  16  train             13.27   0.02     4.12  2.41         0.20      0.29\n",
            "  17  motorcycle         0.01   0.00  6690.88  0.10         0.00      0.91\n",
            "  18  bicycle           21.37   0.16     3.50  0.18         0.22      0.85\n",
            "Mean: 33.98\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            "this : [epoch 0], [val loss 0.47110], [acc 0.86952], [acc_cls 0.42157], [mean_iu 0.33985], [fwavacc 0.77907]\n",
            "best : [epoch 0], [val loss 0.47110], [acc 0.86952], [acc_cls 0.42157], [mean_iu 0.33985], [fwavacc 0.77907]\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            "Class Uniform Percentage: 0.5\n",
            "Class Uniform items per Epoch: 2975\n",
            "cls 0 len 5866\n",
            "cls 1 len 5184\n",
            "cls 2 len 5678\n",
            "cls 3 len 1312\n",
            "cls 4 len 1723\n",
            "cls 5 len 5656\n",
            "cls 6 len 2769\n",
            "cls 7 len 4860\n",
            "cls 8 len 5388\n",
            "cls 9 len 2440\n",
            "cls 10 len 4722\n",
            "cls 11 len 3719\n",
            "cls 12 len 1239\n",
            "cls 13 len 5075\n",
            "cls 14 len 444\n",
            "cls 15 len 348\n",
            "cls 16 len 188\n",
            "cls 17 len 575\n",
            "cls 18 len 2238\n",
            "[epoch 1], [iter 1 / 495], [train main loss -26.806604], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 2 / 495], [train main loss -21.495402], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 3 / 495], [train main loss -22.122232], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 4 / 495], [train main loss -21.326007], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 5 / 495], [train main loss -19.408017], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 6 / 495], [train main loss -20.170365], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 7 / 495], [train main loss -20.024116], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 8 / 495], [train main loss -19.618331], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 9 / 495], [train main loss -19.264375], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 10 / 495], [train main loss -18.424140], [lr 0.003006] [batchtime 0]\n",
            "[epoch 1], [iter 11 / 495], [train main loss -17.922615], [lr 0.003006] [batchtime 2.99]\n",
            "[epoch 1], [iter 12 / 495], [train main loss -17.160140], [lr 0.003006] [batchtime 2.99]\n",
            "[epoch 1], [iter 13 / 495], [train main loss -17.012155], [lr 0.003006] [batchtime 2.99]\n",
            "[epoch 1], [iter 14 / 495], [train main loss -16.694264], [lr 0.003006] [batchtime 2.98]\n",
            "[epoch 1], [iter 15 / 495], [train main loss -16.467711], [lr 0.003006] [batchtime 2.99]\n",
            "[epoch 1], [iter 16 / 495], [train main loss -16.752676], [lr 0.003006] [batchtime 2.98]\n",
            "[epoch 1], [iter 17 / 495], [train main loss -16.902734], [lr 0.003006] [batchtime 2.97]\n",
            "[epoch 1], [iter 18 / 495], [train main loss -17.189736], [lr 0.003006] [batchtime 2.96]\n",
            "[epoch 1], [iter 19 / 495], [train main loss -17.302272], [lr 0.003006] [batchtime 2.96]\n",
            "[epoch 1], [iter 20 / 495], [train main loss -17.250144], [lr 0.003006] [batchtime 2.96]\n",
            "[epoch 1], [iter 21 / 495], [train main loss -17.096551], [lr 0.003006] [batchtime 2.95]\n",
            "[epoch 1], [iter 22 / 495], [train main loss -17.245784], [lr 0.003006] [batchtime 2.95]\n",
            "[epoch 1], [iter 23 / 495], [train main loss -17.106516], [lr 0.003006] [batchtime 2.95]\n",
            "[epoch 1], [iter 24 / 495], [train main loss -17.124594], [lr 0.003006] [batchtime 2.94]\n",
            "[epoch 1], [iter 25 / 495], [train main loss -17.032884], [lr 0.003006] [batchtime 2.94]\n",
            "[epoch 1], [iter 26 / 495], [train main loss -16.911502], [lr 0.003006] [batchtime 2.94]\n",
            "[epoch 1], [iter 27 / 495], [train main loss -16.935412], [lr 0.003006] [batchtime 2.94]\n",
            "[epoch 1], [iter 28 / 495], [train main loss -16.991874], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 29 / 495], [train main loss -16.799038], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 30 / 495], [train main loss -16.708290], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 31 / 495], [train main loss -16.956469], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 32 / 495], [train main loss -16.989493], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 33 / 495], [train main loss -17.061353], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 34 / 495], [train main loss -17.126964], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 35 / 495], [train main loss -16.995191], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 36 / 495], [train main loss -17.037107], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 37 / 495], [train main loss -17.125251], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 38 / 495], [train main loss -17.161404], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 39 / 495], [train main loss -16.977887], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 40 / 495], [train main loss -16.996798], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 41 / 495], [train main loss -16.899300], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 42 / 495], [train main loss -16.793888], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 43 / 495], [train main loss -16.815879], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 44 / 495], [train main loss -16.636006], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 45 / 495], [train main loss -16.591051], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 46 / 495], [train main loss -16.630191], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 47 / 495], [train main loss -16.640368], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 48 / 495], [train main loss -16.729052], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 49 / 495], [train main loss -16.669647], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 50 / 495], [train main loss -16.680999], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 51 / 495], [train main loss -16.636884], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 52 / 495], [train main loss -16.612820], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 53 / 495], [train main loss -16.578151], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 54 / 495], [train main loss -16.539171], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 55 / 495], [train main loss -16.585973], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 56 / 495], [train main loss -16.478888], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 57 / 495], [train main loss -16.416052], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 58 / 495], [train main loss -16.367397], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 59 / 495], [train main loss -16.336242], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 60 / 495], [train main loss -16.153754], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 61 / 495], [train main loss -16.096930], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 62 / 495], [train main loss -16.027791], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 63 / 495], [train main loss -15.894845], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 64 / 495], [train main loss -15.902329], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 65 / 495], [train main loss -15.850086], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 66 / 495], [train main loss -15.943100], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 67 / 495], [train main loss -15.876426], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 68 / 495], [train main loss -15.849963], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 69 / 495], [train main loss -16.002342], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 70 / 495], [train main loss -15.986757], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 71 / 495], [train main loss -15.994963], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 72 / 495], [train main loss -16.056622], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 73 / 495], [train main loss -16.150001], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 74 / 495], [train main loss -16.102892], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 75 / 495], [train main loss -16.083864], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 76 / 495], [train main loss -16.062505], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 77 / 495], [train main loss -16.079017], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 78 / 495], [train main loss -16.147037], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 79 / 495], [train main loss -16.082192], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 80 / 495], [train main loss -16.003577], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 81 / 495], [train main loss -15.948252], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 82 / 495], [train main loss -15.968057], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 83 / 495], [train main loss -15.924864], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 84 / 495], [train main loss -15.930221], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 85 / 495], [train main loss -15.988111], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 86 / 495], [train main loss -15.993245], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 87 / 495], [train main loss -15.968121], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 88 / 495], [train main loss -16.009319], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 89 / 495], [train main loss -15.943623], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 90 / 495], [train main loss -15.930196], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 91 / 495], [train main loss -15.881888], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 92 / 495], [train main loss -15.942364], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 93 / 495], [train main loss -15.943619], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 94 / 495], [train main loss -15.983273], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 95 / 495], [train main loss -16.060490], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 96 / 495], [train main loss -16.002695], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 97 / 495], [train main loss -16.022793], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 98 / 495], [train main loss -15.989383], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 99 / 495], [train main loss -15.972097], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 100 / 495], [train main loss -15.990357], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 101 / 495], [train main loss -16.040998], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 102 / 495], [train main loss -16.049292], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 103 / 495], [train main loss -15.990090], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 104 / 495], [train main loss -15.986121], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 105 / 495], [train main loss -15.991650], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 106 / 495], [train main loss -15.921208], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 107 / 495], [train main loss -15.892764], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 108 / 495], [train main loss -15.863025], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 109 / 495], [train main loss -15.881310], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 110 / 495], [train main loss -15.861852], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 111 / 495], [train main loss -15.908052], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 112 / 495], [train main loss -15.925497], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 113 / 495], [train main loss -15.934498], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 114 / 495], [train main loss -15.937843], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 115 / 495], [train main loss -15.988376], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 116 / 495], [train main loss -15.964419], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 117 / 495], [train main loss -15.928431], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 118 / 495], [train main loss -15.938034], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 119 / 495], [train main loss -15.949514], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 120 / 495], [train main loss -15.961265], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 121 / 495], [train main loss -15.946791], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 122 / 495], [train main loss -15.918997], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 123 / 495], [train main loss -15.894474], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 124 / 495], [train main loss -15.943456], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 125 / 495], [train main loss -15.918457], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 126 / 495], [train main loss -15.945024], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 127 / 495], [train main loss -15.965597], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 128 / 495], [train main loss -15.988731], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 129 / 495], [train main loss -16.004615], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 130 / 495], [train main loss -15.981197], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 131 / 495], [train main loss -15.938030], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 132 / 495], [train main loss -15.934524], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 133 / 495], [train main loss -15.941222], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 134 / 495], [train main loss -15.934481], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 135 / 495], [train main loss -15.902356], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 136 / 495], [train main loss -15.894464], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 137 / 495], [train main loss -15.893539], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 138 / 495], [train main loss -15.876020], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 139 / 495], [train main loss -15.856020], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 140 / 495], [train main loss -15.860353], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 141 / 495], [train main loss -15.864500], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 142 / 495], [train main loss -15.867195], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 143 / 495], [train main loss -15.901336], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 144 / 495], [train main loss -15.931027], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 145 / 495], [train main loss -15.882412], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 146 / 495], [train main loss -15.916944], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 147 / 495], [train main loss -15.925496], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 148 / 495], [train main loss -15.944633], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 149 / 495], [train main loss -15.890645], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 150 / 495], [train main loss -15.858698], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 151 / 495], [train main loss -15.839030], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 152 / 495], [train main loss -15.824078], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 153 / 495], [train main loss -15.823740], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 154 / 495], [train main loss -15.803718], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 155 / 495], [train main loss -15.825273], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 156 / 495], [train main loss -15.814586], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 157 / 495], [train main loss -15.810176], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 158 / 495], [train main loss -15.793893], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 159 / 495], [train main loss -15.772234], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 160 / 495], [train main loss -15.805169], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 161 / 495], [train main loss -15.795345], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 162 / 495], [train main loss -15.813529], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 163 / 495], [train main loss -15.825846], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 164 / 495], [train main loss -15.797841], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 165 / 495], [train main loss -15.780260], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 166 / 495], [train main loss -15.833924], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 167 / 495], [train main loss -15.840796], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 168 / 495], [train main loss -15.839661], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 169 / 495], [train main loss -15.860951], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 170 / 495], [train main loss -15.889460], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 171 / 495], [train main loss -15.892895], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 172 / 495], [train main loss -15.903001], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 173 / 495], [train main loss -15.886507], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 174 / 495], [train main loss -15.883797], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 175 / 495], [train main loss -15.838119], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 176 / 495], [train main loss -15.835936], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 177 / 495], [train main loss -15.793255], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 178 / 495], [train main loss -15.754685], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 179 / 495], [train main loss -15.721523], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 180 / 495], [train main loss -15.738226], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 181 / 495], [train main loss -15.723565], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 182 / 495], [train main loss -15.733600], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 183 / 495], [train main loss -15.682873], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 184 / 495], [train main loss -15.671278], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 185 / 495], [train main loss -15.664649], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 186 / 495], [train main loss -15.724587], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 187 / 495], [train main loss -15.707332], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 188 / 495], [train main loss -15.730665], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 189 / 495], [train main loss -15.750058], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 190 / 495], [train main loss -15.779497], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 191 / 495], [train main loss -15.792736], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 192 / 495], [train main loss -15.773634], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 193 / 495], [train main loss -15.724369], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 194 / 495], [train main loss -15.738554], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 195 / 495], [train main loss -15.747726], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 196 / 495], [train main loss -15.767042], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 197 / 495], [train main loss -15.748825], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 198 / 495], [train main loss -15.721729], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 199 / 495], [train main loss -15.727160], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 200 / 495], [train main loss -15.744087], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 201 / 495], [train main loss -15.763768], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 202 / 495], [train main loss -15.788378], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 203 / 495], [train main loss -15.794410], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 204 / 495], [train main loss -15.800813], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 205 / 495], [train main loss -15.810001], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 206 / 495], [train main loss -15.796785], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 207 / 495], [train main loss -15.770172], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 208 / 495], [train main loss -15.771914], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 209 / 495], [train main loss -15.772643], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 210 / 495], [train main loss -15.781763], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 211 / 495], [train main loss -15.769919], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 212 / 495], [train main loss -15.804098], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 213 / 495], [train main loss -15.821708], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 214 / 495], [train main loss -15.829053], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 215 / 495], [train main loss -15.857027], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 216 / 495], [train main loss -15.863288], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 217 / 495], [train main loss -15.878595], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 218 / 495], [train main loss -15.887877], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 219 / 495], [train main loss -15.894261], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 220 / 495], [train main loss -15.867129], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 221 / 495], [train main loss -15.859649], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 222 / 495], [train main loss -15.880032], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 223 / 495], [train main loss -15.890466], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 224 / 495], [train main loss -15.873048], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 225 / 495], [train main loss -15.877580], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 226 / 495], [train main loss -15.886843], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 227 / 495], [train main loss -15.888654], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 228 / 495], [train main loss -15.869799], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 229 / 495], [train main loss -15.871826], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 230 / 495], [train main loss -15.862404], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 231 / 495], [train main loss -15.870994], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 232 / 495], [train main loss -15.848579], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 233 / 495], [train main loss -15.862505], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 234 / 495], [train main loss -15.876166], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 235 / 495], [train main loss -15.888077], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 236 / 495], [train main loss -15.892025], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 237 / 495], [train main loss -15.911720], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 238 / 495], [train main loss -15.882777], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 239 / 495], [train main loss -15.888281], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 240 / 495], [train main loss -15.868036], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 241 / 495], [train main loss -15.869949], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 242 / 495], [train main loss -15.865539], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 243 / 495], [train main loss -15.844539], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 244 / 495], [train main loss -15.829501], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 245 / 495], [train main loss -15.846877], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 246 / 495], [train main loss -15.827025], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 247 / 495], [train main loss -15.835560], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 248 / 495], [train main loss -15.839771], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 249 / 495], [train main loss -15.836759], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 250 / 495], [train main loss -15.834969], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 251 / 495], [train main loss -15.853673], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 252 / 495], [train main loss -15.886266], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 253 / 495], [train main loss -15.884402], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 254 / 495], [train main loss -15.875730], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 255 / 495], [train main loss -15.857885], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 256 / 495], [train main loss -15.832058], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 257 / 495], [train main loss -15.844417], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 258 / 495], [train main loss -15.861921], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 259 / 495], [train main loss -15.880563], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 260 / 495], [train main loss -15.869840], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 261 / 495], [train main loss -15.867178], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 262 / 495], [train main loss -15.878137], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 263 / 495], [train main loss -15.874358], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 264 / 495], [train main loss -15.867630], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 265 / 495], [train main loss -15.879867], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 266 / 495], [train main loss -15.871789], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 267 / 495], [train main loss -15.886043], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 268 / 495], [train main loss -15.893946], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 269 / 495], [train main loss -15.888840], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 270 / 495], [train main loss -15.868723], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 271 / 495], [train main loss -15.889024], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 272 / 495], [train main loss -15.883811], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 273 / 495], [train main loss -15.882391], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 274 / 495], [train main loss -15.887463], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 275 / 495], [train main loss -15.920208], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 276 / 495], [train main loss -15.899483], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 277 / 495], [train main loss -15.919756], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 278 / 495], [train main loss -15.938679], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 279 / 495], [train main loss -15.960742], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 280 / 495], [train main loss -15.947509], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 281 / 495], [train main loss -15.946194], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 282 / 495], [train main loss -15.932528], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 283 / 495], [train main loss -15.930716], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 284 / 495], [train main loss -15.930149], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 285 / 495], [train main loss -15.915807], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 286 / 495], [train main loss -15.935018], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 287 / 495], [train main loss -15.937292], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 288 / 495], [train main loss -15.910624], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 289 / 495], [train main loss -15.930278], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 290 / 495], [train main loss -15.919770], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 291 / 495], [train main loss -15.930096], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 292 / 495], [train main loss -15.947222], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 293 / 495], [train main loss -15.940509], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 294 / 495], [train main loss -15.938282], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 295 / 495], [train main loss -15.926910], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 296 / 495], [train main loss -15.923073], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 297 / 495], [train main loss -15.940883], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 298 / 495], [train main loss -15.928682], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 299 / 495], [train main loss -15.939679], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 300 / 495], [train main loss -15.929952], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 301 / 495], [train main loss -15.921411], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 302 / 495], [train main loss -15.919493], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 303 / 495], [train main loss -15.938202], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 304 / 495], [train main loss -15.925588], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 305 / 495], [train main loss -15.904723], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 306 / 495], [train main loss -15.892357], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 307 / 495], [train main loss -15.879096], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 308 / 495], [train main loss -15.865304], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 309 / 495], [train main loss -15.850383], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 310 / 495], [train main loss -15.837001], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 311 / 495], [train main loss -15.858619], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 312 / 495], [train main loss -15.862947], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 313 / 495], [train main loss -15.879112], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 314 / 495], [train main loss -15.880897], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 315 / 495], [train main loss -15.858563], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 316 / 495], [train main loss -15.847273], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 317 / 495], [train main loss -15.866854], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 318 / 495], [train main loss -15.887390], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 319 / 495], [train main loss -15.892271], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 320 / 495], [train main loss -15.885724], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 321 / 495], [train main loss -15.887116], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 322 / 495], [train main loss -15.890062], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 323 / 495], [train main loss -15.899293], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 324 / 495], [train main loss -15.898311], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 325 / 495], [train main loss -15.916299], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 326 / 495], [train main loss -15.900116], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 327 / 495], [train main loss -15.912813], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 328 / 495], [train main loss -15.900129], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 329 / 495], [train main loss -15.911685], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 330 / 495], [train main loss -15.921010], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 331 / 495], [train main loss -15.930349], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 332 / 495], [train main loss -15.915876], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 333 / 495], [train main loss -15.905869], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 334 / 495], [train main loss -15.880501], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 335 / 495], [train main loss -15.895959], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 336 / 495], [train main loss -15.889745], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 337 / 495], [train main loss -15.894370], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 338 / 495], [train main loss -15.873536], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 339 / 495], [train main loss -15.883524], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 340 / 495], [train main loss -15.880683], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 341 / 495], [train main loss -15.870324], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 342 / 495], [train main loss -15.874889], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 343 / 495], [train main loss -15.891196], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 344 / 495], [train main loss -15.895331], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 345 / 495], [train main loss -15.895295], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 346 / 495], [train main loss -15.890089], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 347 / 495], [train main loss -15.888050], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 348 / 495], [train main loss -15.875603], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 349 / 495], [train main loss -15.866764], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 350 / 495], [train main loss -15.867443], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 351 / 495], [train main loss -15.882607], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 352 / 495], [train main loss -15.880860], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 353 / 495], [train main loss -15.879056], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 354 / 495], [train main loss -15.855767], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 355 / 495], [train main loss -15.845080], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 356 / 495], [train main loss -15.862135], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 357 / 495], [train main loss -15.877591], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 358 / 495], [train main loss -15.880117], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 359 / 495], [train main loss -15.872592], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 360 / 495], [train main loss -15.868378], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 361 / 495], [train main loss -15.879436], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 362 / 495], [train main loss -15.878852], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 363 / 495], [train main loss -15.873897], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 364 / 495], [train main loss -15.845021], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 365 / 495], [train main loss -15.842642], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 366 / 495], [train main loss -15.864666], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 367 / 495], [train main loss -15.880193], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 368 / 495], [train main loss -15.882952], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 369 / 495], [train main loss -15.873547], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 370 / 495], [train main loss -15.873999], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 371 / 495], [train main loss -15.868168], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 372 / 495], [train main loss -15.877303], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 373 / 495], [train main loss -15.892520], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 374 / 495], [train main loss -15.890607], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 375 / 495], [train main loss -15.910596], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 376 / 495], [train main loss -15.924004], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 377 / 495], [train main loss -15.905877], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 378 / 495], [train main loss -15.898080], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 379 / 495], [train main loss -15.906656], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 380 / 495], [train main loss -15.926316], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 381 / 495], [train main loss -15.923347], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 382 / 495], [train main loss -15.937280], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 383 / 495], [train main loss -15.925630], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 384 / 495], [train main loss -15.912771], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 385 / 495], [train main loss -15.926129], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 386 / 495], [train main loss -15.923026], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 387 / 495], [train main loss -15.920039], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 388 / 495], [train main loss -15.931243], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 389 / 495], [train main loss -15.919156], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 390 / 495], [train main loss -15.905817], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 391 / 495], [train main loss -15.913983], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 392 / 495], [train main loss -15.897472], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 393 / 495], [train main loss -15.909825], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 394 / 495], [train main loss -15.926017], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 395 / 495], [train main loss -15.914837], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 396 / 495], [train main loss -15.923762], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 397 / 495], [train main loss -15.929904], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 398 / 495], [train main loss -15.929773], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 399 / 495], [train main loss -15.919875], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 400 / 495], [train main loss -15.944783], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 401 / 495], [train main loss -15.948203], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 402 / 495], [train main loss -15.952688], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 403 / 495], [train main loss -15.940716], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 404 / 495], [train main loss -15.952240], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 405 / 495], [train main loss -15.958591], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 406 / 495], [train main loss -15.951003], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 407 / 495], [train main loss -15.941966], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 408 / 495], [train main loss -15.937078], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 409 / 495], [train main loss -15.942220], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 410 / 495], [train main loss -15.933126], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 411 / 495], [train main loss -15.937921], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 412 / 495], [train main loss -15.914968], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 413 / 495], [train main loss -15.897299], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 414 / 495], [train main loss -15.923465], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 415 / 495], [train main loss -15.929528], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 416 / 495], [train main loss -15.933791], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 417 / 495], [train main loss -15.928119], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 418 / 495], [train main loss -15.938821], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 419 / 495], [train main loss -15.928843], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 420 / 495], [train main loss -15.940957], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 421 / 495], [train main loss -15.945688], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 422 / 495], [train main loss -15.954759], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 423 / 495], [train main loss -15.970713], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 424 / 495], [train main loss -15.968994], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 425 / 495], [train main loss -15.976681], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 426 / 495], [train main loss -15.961671], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 427 / 495], [train main loss -15.960329], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 428 / 495], [train main loss -15.956790], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 429 / 495], [train main loss -15.956333], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 430 / 495], [train main loss -15.951136], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 431 / 495], [train main loss -15.947078], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 432 / 495], [train main loss -15.943476], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 433 / 495], [train main loss -15.937503], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 434 / 495], [train main loss -15.930605], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 435 / 495], [train main loss -15.927575], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 436 / 495], [train main loss -15.939394], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 437 / 495], [train main loss -15.939794], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 438 / 495], [train main loss -15.951038], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 439 / 495], [train main loss -15.971622], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 440 / 495], [train main loss -15.968881], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 441 / 495], [train main loss -15.966116], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 442 / 495], [train main loss -15.966626], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 443 / 495], [train main loss -15.962809], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 444 / 495], [train main loss -15.971491], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 445 / 495], [train main loss -15.957984], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 446 / 495], [train main loss -15.955067], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 447 / 495], [train main loss -15.959593], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 448 / 495], [train main loss -15.949346], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 449 / 495], [train main loss -15.943866], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 450 / 495], [train main loss -15.938137], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 451 / 495], [train main loss -15.937780], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 452 / 495], [train main loss -15.942379], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 453 / 495], [train main loss -15.947401], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 454 / 495], [train main loss -15.947200], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 455 / 495], [train main loss -15.939075], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 456 / 495], [train main loss -15.934955], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 457 / 495], [train main loss -15.928961], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 458 / 495], [train main loss -15.928917], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 459 / 495], [train main loss -15.948760], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 460 / 495], [train main loss -15.948153], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 461 / 495], [train main loss -15.955918], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 462 / 495], [train main loss -15.956525], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 463 / 495], [train main loss -15.957421], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 464 / 495], [train main loss -15.948359], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 465 / 495], [train main loss -15.959796], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 466 / 495], [train main loss -15.972281], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 467 / 495], [train main loss -15.974353], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 468 / 495], [train main loss -15.967355], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 469 / 495], [train main loss -15.975001], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 470 / 495], [train main loss -15.978402], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 471 / 495], [train main loss -15.974522], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 472 / 495], [train main loss -15.968622], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 473 / 495], [train main loss -15.972799], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 474 / 495], [train main loss -15.987283], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 475 / 495], [train main loss -15.995570], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 476 / 495], [train main loss -15.991044], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 477 / 495], [train main loss -16.010815], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 478 / 495], [train main loss -16.001028], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 479 / 495], [train main loss -15.998360], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 480 / 495], [train main loss -15.999546], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 481 / 495], [train main loss -15.981668], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 482 / 495], [train main loss -15.999762], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 483 / 495], [train main loss -15.989703], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 484 / 495], [train main loss -15.997321], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 485 / 495], [train main loss -15.989387], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 486 / 495], [train main loss -15.987445], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 487 / 495], [train main loss -15.984903], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 488 / 495], [train main loss -15.972629], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 489 / 495], [train main loss -15.980575], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 490 / 495], [train main loss -15.982169], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 491 / 495], [train main loss -15.973975], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 492 / 495], [train main loss -15.975662], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 493 / 495], [train main loss -15.973456], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 494 / 495], [train main loss -15.978913], [lr 0.003006] [batchtime 2.93]\n",
            "[epoch 1], [iter 495 / 495], [train main loss -15.981646], [lr 0.003006] [batchtime 2.93]\n",
            "validating[Iter: 1 / 500]\n",
            "validating[Iter: 21 / 500]\n",
            "validating[Iter: 41 / 500]\n",
            "validating[Iter: 61 / 500]\n",
            "validating[Iter: 81 / 500]\n",
            "validating[Iter: 101 / 500]\n",
            "validating[Iter: 121 / 500]\n",
            "validating[Iter: 141 / 500]\n",
            "validating[Iter: 161 / 500]\n",
            "validating[Iter: 181 / 500]\n",
            "validating[Iter: 201 / 500]\n",
            "validating[Iter: 221 / 500]\n",
            "validating[Iter: 241 / 500]\n",
            "validating[Iter: 261 / 500]\n",
            "validating[Iter: 281 / 500]\n",
            "validating[Iter: 301 / 500]\n",
            "validating[Iter: 321 / 500]\n",
            "validating[Iter: 341 / 500]\n",
            "validating[Iter: 361 / 500]\n",
            "validating[Iter: 381 / 500]\n",
            "validating[Iter: 401 / 500]\n",
            "validating[Iter: 421 / 500]\n",
            "validating[Iter: 441 / 500]\n",
            "validating[Iter: 461 / 500]\n",
            "validating[Iter: 481 / 500]\n",
            "IoU:\n",
            "  Id  label            iU_1.0     TP        FP     FN    Precision    Recall\n",
            "----  -------------  --------  -----  --------  -----  -----------  --------\n",
            "   0  road              92.63  36.99      0.02   0.06         0.98      0.94\n",
            "   1  sidewalk          53.85   3.33      0.62   0.23         0.62      0.81\n",
            "   2  building          79.34  19.52      0.12   0.14         0.89      0.88\n",
            "   3  wall               3.57   0.03     26.62   0.40         0.04      0.71\n",
            "   4  fence             12.48   0.11      6.61   0.41         0.13      0.71\n",
            "   5  pole              39.93   0.83      0.79   0.72         0.56      0.58\n",
            "   6  traffic light      4.86   0.01     19.10   0.48         0.05      0.68\n",
            "   7  traffic sign      10.33   0.07      8.16   0.51         0.11      0.66\n",
            "   8  vegetation        80.12  14.49      0.20   0.05         0.84      0.95\n",
            "   9  terrain           32.65   0.42      0.97   1.10         0.51      0.48\n",
            "  10  sky               79.21   3.29      0.02   0.24         0.98      0.80\n",
            "  11  person            29.04   1.10      0.18   2.26         0.84      0.31\n",
            "  12  rider              0.15   0.00    677.90   1.23         0.00      0.45\n",
            "  13  car               70.17   6.20      0.05   0.38         0.95      0.73\n",
            "  14  truck              0.00   0.00  62731.07  18.25         0.00      0.05\n",
            "  15  bus                1.72   0.01     56.44   0.77         0.02      0.57\n",
            "  16  train              1.90   0.00     50.80   0.93         0.02      0.52\n",
            "  17  motorcycle         0.40   0.00    247.02   1.84         0.00      0.35\n",
            "  18  bicycle           32.91   0.26      1.74   0.30         0.37      0.77\n",
            "Mean: 32.91\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            "this : [epoch 1], [val loss 0.49620], [acc 0.86654], [acc_cls 0.41606], [mean_iu 0.32908], [fwavacc 0.77977]\n",
            "best : [epoch 0], [val loss 0.47110], [acc 0.86952], [acc_cls 0.42157], [mean_iu 0.33985], [fwavacc 0.77907]\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            "Class Uniform Percentage: 0.5\n",
            "Class Uniform items per Epoch: 2975\n",
            "cls 0 len 5866\n",
            "cls 1 len 5184\n",
            "cls 2 len 5678\n",
            "cls 3 len 1312\n",
            "cls 4 len 1723\n",
            "cls 5 len 5656\n",
            "cls 6 len 2769\n",
            "cls 7 len 4860\n",
            "cls 8 len 5388\n",
            "cls 9 len 2440\n",
            "cls 10 len 4722\n",
            "cls 11 len 3719\n",
            "cls 12 len 1239\n",
            "cls 13 len 5075\n",
            "cls 14 len 444\n",
            "cls 15 len 348\n",
            "cls 16 len 188\n",
            "cls 17 len 575\n",
            "cls 18 len 2238\n",
            "[epoch 2], [iter 1 / 495], [train main loss -22.337572], [lr 0.002946] [batchtime 0]\n",
            "[epoch 2], [iter 2 / 495], [train main loss -22.651323], [lr 0.002946] [batchtime 0]\n",
            "[epoch 2], [iter 3 / 495], [train main loss -22.619347], [lr 0.002946] [batchtime 0]\n",
            "[epoch 2], [iter 4 / 495], [train main loss -23.047760], [lr 0.002946] [batchtime 0]\n",
            "[epoch 2], [iter 5 / 495], [train main loss -23.896439], [lr 0.002946] [batchtime 0]\n",
            "Killing subprocess 5031\n",
            "Main process received SIGINT, exiting\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/runx/runx.py\", line 413, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/runx/runx.py\", line 406, in main\n",
            "    run_experiment(args.exp_yml)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/runx/runx.py\", line 399, in run_experiment\n",
            "    run_yaml(experiment_copy, exp_name, runroot)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/runx/runx.py\", line 346, in run_yaml\n",
            "    exec_cmd(cmd)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/runx/runx.py\", line 98, in exec_cmd\n",
            "    result = subprocess.run(cmd, stderr=subprocess.PIPE, shell=True)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 490, in run\n",
            "    stdout, stderr = process.communicate(input, timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 954, in communicate\n",
            "    stderr = self.stderr.read()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8aQ_XmYZ0vj"
      },
      "source": [
        "# upload results to google cloud bucket\n",
        "# !gsutil -m cp -r /content/uniform_centroids/* gs://csc413-final-project-cityscapes-data/uniform_centroids/\n",
        "!gsutil -m cp -r /content/drive/MyDrive/CSC413FinalProject/HMSA/logs/train_cityscapes/* gs://csc413-final-project-hmsa-weights/training_results/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc1I_a--cbKF"
      },
      "source": [
        "# folder name: jasper-ocelot"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}