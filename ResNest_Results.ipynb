{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNest_Results.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qeSpIOry4YM5","executionInfo":{"status":"ok","timestamp":1618716134483,"user_tz":240,"elapsed":369861,"user":{"displayName":"Jennifer Kong","photoUrl":"","userId":"14455942005526959470"}},"outputId":"f37b25ca-c030-44be-e8af-87278f313efa"},"source":["!pip install torch==1.4.0 torchvision==0.5.0 ninja torch-encoding\n","!pip install git+https://github.com/zhanghang1989/PyTorch-Encoding/\n","!pip install git+https://github.com/facebookresearch/fvcore.git"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n","Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.7/dist-packages (0.5.0)\n","Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (1.10.0.post2)\n","Requirement already satisfied: torch-encoding in /usr/local/lib/python3.7/dist-packages (1.2.2b20210418)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n","Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from torch-encoding) (1.3.7)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-encoding) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-encoding) (2.23.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from torch-encoding) (2.3.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-encoding) (4.41.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding) (2.10)\n","Collecting git+https://github.com/zhanghang1989/PyTorch-Encoding/\n","  Cloning https://github.com/zhanghang1989/PyTorch-Encoding/ to /tmp/pip-req-build-kygb_f52\n","  Running command git clone -q https://github.com/zhanghang1989/PyTorch-Encoding/ /tmp/pip-req-build-kygb_f52\n","Requirement already satisfied (use --upgrade to upgrade): torch-encoding==1.2.2b20210418 from git+https://github.com/zhanghang1989/PyTorch-Encoding/ in /usr/local/lib/python3.7/dist-packages\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (1.19.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (4.41.1)\n","Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (1.3.7)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (2.3.0)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (1.4.0)\n","Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (0.5.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (7.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-encoding==1.2.2b20210418) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->torch-encoding==1.2.2b20210418) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210418) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210418) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210418) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-encoding==1.2.2b20210418) (3.0.4)\n","Building wheels for collected packages: torch-encoding\n","  Building wheel for torch-encoding (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-encoding: filename=torch_encoding-1.2.2b20210418-cp37-cp37m-linux_x86_64.whl size=7347175 sha256=b4be4af21d78222465b06cf4c341b38901a397a31d1fcb5a3b94bbbb87c05372\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-aom21gtw/wheels/f8/4f/46/924a4c89ee95252b34c3e257f1de2664a053e52c5aa5013d4a\n","Successfully built torch-encoding\n","Collecting git+https://github.com/facebookresearch/fvcore.git\n","  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-01jjs_a1\n","  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-01jjs_a1\n","Requirement already satisfied (use --upgrade to upgrade): fvcore==0.1.5 from git+https://github.com/facebookresearch/fvcore.git in /usr/local/lib/python3.7/dist-packages\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (1.19.5)\n","Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (0.1.8)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (5.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (4.41.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (1.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (7.1.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (0.8.9)\n","Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.5) (0.1.8)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.7->fvcore==0.1.5) (2.3.0)\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5-cp37-none-any.whl size=63180 sha256=f59e63da93e5004c7111172d1b0d81c51418c641a4ad5856ce29fddc3a447c09\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-mmus71m5/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n","Successfully built fvcore\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iHWinswa4H85","executionInfo":{"status":"ok","timestamp":1618716179772,"user_tz":240,"elapsed":728,"user":{"displayName":"Jennifer Kong","photoUrl":"","userId":"14455942005526959470"}}},"source":["import warnings\n","try:\n","    from queue import Queue\n","except ImportError:\n","    from Queue import Queue\n","\n","import torch\n","from torch.nn.modules.batchnorm import _BatchNorm\n","\n","from encoding.utils.misc import EncodingDeprecationWarning\n","from encoding.functions import *\n","\n","class DistSyncBatchNorm(_BatchNorm):\n","    r\"\"\"Cross-GPU Synchronized Batch normalization (SyncBN)\n","\n","    Standard BN [1]_ implementation only normalize the data within each device (GPU).\n","    SyncBN normalizes the input within the whole mini-batch.\n","    We follow the sync-onece implmentation described in the paper [2]_ .\n","    Please see the design idea in the `notes <./notes/syncbn.html>`_.\n","\n","    .. math::\n","\n","        y = \\frac{x - mean[x]}{ \\sqrt{Var[x] + \\epsilon}} * gamma + beta\n","\n","    The mean and standard-deviation are calculated per-channel over\n","    the mini-batches and gamma and beta are learnable parameter vectors\n","    of size C (where C is the input size).\n","\n","    During training, this layer keeps a running estimate of its computed mean\n","    and variance. The running sum is kept with a default momentum of 0.1.\n","\n","    During evaluation, this running mean/variance is used for normalization.\n","\n","    Because the BatchNorm is done over the `C` dimension, computing statistics\n","    on `(N, H, W)` slices, it's common terminology to call this Spatial BatchNorm\n","\n","    Args:\n","        num_features: num_features from an expected input of\n","            size batch_size x num_features x height x width\n","        eps: a value added to the denominator for numerical stability.\n","            Default: 1e-5\n","        momentum: the value used for the running_mean and running_var\n","            computation. Default: 0.1\n","        sync: a boolean value that when set to ``True``, synchronize across\n","            different gpus. Default: ``True``\n","        activation : str\n","            Name of the activation functions, one of: `leaky_relu` or `none`.\n","        slope : float\n","            Negative slope for the `leaky_relu` activation.\n","\n","    Shape:\n","        - Input: :math:`(N, C, H, W)`\n","        - Output: :math:`(N, C, H, W)` (same shape as input)\n","\n","    Reference:\n","        .. [1] Ioffe, Sergey, and Christian Szegedy. \"Batch normalization: Accelerating deep network training by reducing internal covariate shift.\" *ICML 2015*\n","        .. [2] Hang Zhang, Kristin Dana, Jianping Shi, Zhongyue Zhang, Xiaogang Wang, Ambrish Tyagi, and Amit Agrawal. \"Context Encoding for Semantic Segmentation.\" *CVPR 2018*\n","\n","    Examples:\n","        >>> m = DistSyncBatchNorm(100)\n","        >>> net = torch.nn.parallel.DistributedDataParallel(m)\n","        >>> output = net(input)\n","    \"\"\"\n","    def __init__(self, num_features, eps=1e-5, momentum=0.1, process_group=None):\n","        super(DistSyncBatchNorm, self).__init__(num_features, eps=eps, momentum=momentum, affine=True, track_running_stats=True)\n","        self.process_group = process_group\n","\n","    def forward(self, x):\n","        need_sync = self.training or not self.track_running_stats\n","        process_group = None\n","        if need_sync:\n","            process_group = torch.distributed.group.WORLD\n","            if self.process_group:\n","                process_group = self.process_group\n","            world_size = torch.distributed.get_world_size(process_group)\n","            need_sync = world_size > 1\n","\n","        # Resize the input to (B, C, -1).\n","        input_shape = x.size()\n","        x = x.view(input_shape[0], self.num_features, -1)\n","        #def forward(ctx, x, gamma, beta, running_mean, running_var, eps, momentum, training, process_group):\n","        y = dist_syncbatchnorm(x, self.weight, self.bias, self.running_mean, self.running_var,\n","                               self.eps, self.momentum, self.training, process_group)\n","\n","        #_var = _exs - _ex ** 2\n","        #running_mean.mul_((1 - ctx.momentum)).add_(ctx.momentum * _ex)\n","        #running_var.mul_((1 - ctx.momentum)).add_(ctx.momentum * _var)\n","        return y.view(input_shape)\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Ny6tEIt4iBj","executionInfo":{"status":"ok","timestamp":1618716196870,"user_tz":240,"elapsed":1098,"user":{"displayName":"Jennifer Kong","photoUrl":"","userId":"14455942005526959470"}}},"source":["import encoding\n","model = encoding.models.get_segmentation_model('deeplab', dataset='citys',\n","                                   backbone=\"resnest50\", aux='True',\n","                                   se_loss='False', norm_layer=DistSyncBatchNorm,\n","                                   base_size=520, crop_size=248)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"O0FXGAqWLhDF","executionInfo":{"status":"ok","timestamp":1618716198625,"user_tz":240,"elapsed":302,"user":{"displayName":"Jennifer Kong","photoUrl":"","userId":"14455942005526959470"}}},"source":["import torch\n","torch.cuda.empty_cache()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zMWupDt1AmGL","executionInfo":{"status":"ok","timestamp":1618716335213,"user_tz":240,"elapsed":784,"user":{"displayName":"Jennifer Kong","photoUrl":"","userId":"14455942005526959470"}}},"source":["checkpoint = torch.load('/content/drive/MyDrive/model_best.pth(1).tar')\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"jsPcsAMyB7fu","executionInfo":{"status":"ok","timestamp":1618716564252,"user_tz":240,"elapsed":5416,"user":{"displayName":"Jennifer Kong","photoUrl":"","userId":"14455942005526959470"}}},"source":["torch.cuda.empty_cache()\n","\n","# Get the model\n","with torch.no_grad():\n","    checkpoint = torch.load('/content/drive/MyDrive/model_best.pth(9).tar')\n","    model.load_state_dict(checkpoint['state_dict'])\n","    model.eval()\n","    model.cuda()\n","\n","# Prepare the image\n","filename = '/content/munster_000000_000019_leftImg8bitpng.png'\n","img = encoding.utils.load_image(filename).cuda().unsqueeze(0)\n","\n","# Make prediction\n","output = model.evaluate(img.cuda())\n","predict = torch.max(output, 1)[1].cpu().numpy() + 1\n","\n","# Get color pallete for visualization\n","mask = encoding.utils.get_mask_pallete(predict, 'citys')\n","mask.save('/content/output_{}.png'.format(checkpoint[\"epoch\"]))"],"execution_count":22,"outputs":[]}]}