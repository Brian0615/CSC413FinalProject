{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ResNest_FT","provenance":[{"file_id":"1OwDAsk1TTfXkXOjrv7rzfPzIFtwsM0oC","timestamp":1618778000028}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40S6okodJsQG","executionInfo":{"status":"ok","timestamp":1618779369018,"user_tz":240,"elapsed":33671,"user":{"displayName":"Innovation Cell","photoUrl":"","userId":"16088182508919568090"}},"outputId":"d47eaaec-c552-4544-b173-fd4c665db616"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEVM3HOyHqnQ","outputId":"c0dd0061-f9dc-4168-805a-6cbb4a348275"},"source":["!pip install torch==1.4.0 torchvision==0.5.0 ninja torch-encoding"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torch==1.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n","\u001b[K     |█████████████              "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UDGtAkMxHyIR"},"source":["%cd /content/\n","!git clone https://github.com/zhanghang1989/PyTorch-Encoding\n","%cd /content/PyTorch-Encoding/\n","!python setup.py clean\n","!python setup.py install\n","!pip install git+https://github.com/zhanghang1989/PyTorch-Encoding/\n","!pip install git+https://github.com/facebookresearch/fvcore.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YkJvZo44WpsY"},"source":["%cd /content/drive/MyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uyKnunx0vNeb"},"source":["!nvidia-smi -L"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qJ41L-rIJxcX"},"source":["!python /content/PyTorch-Encoding/experiments/segmentation/train_dist.py --dataset citys --resume \"/content/runs/citys/deeplab/resnest50/default/model_best.pth.tar\" --model deeplab --aux --backbone resnest50 --crop-size 248 --batch-size 8 --epochs 110"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iOEH-Y2OYKTj"},"source":["import warnings\n","try:\n","    from queue import Queue\n","except ImportError:\n","    from Queue import Queue\n","\n","import torch\n","from torch.nn.modules.batchnorm import _BatchNorm\n","\n","from encoding.utils.misc import EncodingDeprecationWarning\n","from encoding.functions import *\n","\n","class DistSyncBatchNorm(_BatchNorm):\n","    r\"\"\"Cross-GPU Synchronized Batch normalization (SyncBN)\n","\n","    Standard BN [1]_ implementation only normalize the data within each device (GPU).\n","    SyncBN normalizes the input within the whole mini-batch.\n","    We follow the sync-onece implmentation described in the paper [2]_ .\n","    Please see the design idea in the `notes <./notes/syncbn.html>`_.\n","\n","    .. math::\n","\n","        y = \\frac{x - mean[x]}{ \\sqrt{Var[x] + \\epsilon}} * gamma + beta\n","\n","    The mean and standard-deviation are calculated per-channel over\n","    the mini-batches and gamma and beta are learnable parameter vectors\n","    of size C (where C is the input size).\n","\n","    During training, this layer keeps a running estimate of its computed mean\n","    and variance. The running sum is kept with a default momentum of 0.1.\n","\n","    During evaluation, this running mean/variance is used for normalization.\n","\n","    Because the BatchNorm is done over the `C` dimension, computing statistics\n","    on `(N, H, W)` slices, it's common terminology to call this Spatial BatchNorm\n","\n","    Args:\n","        num_features: num_features from an expected input of\n","            size batch_size x num_features x height x width\n","        eps: a value added to the denominator for numerical stability.\n","            Default: 1e-5\n","        momentum: the value used for the running_mean and running_var\n","            computation. Default: 0.1\n","        sync: a boolean value that when set to ``True``, synchronize across\n","            different gpus. Default: ``True``\n","        activation : str\n","            Name of the activation functions, one of: `leaky_relu` or `none`.\n","        slope : float\n","            Negative slope for the `leaky_relu` activation.\n","\n","    Shape:\n","        - Input: :math:`(N, C, H, W)`\n","        - Output: :math:`(N, C, H, W)` (same shape as input)\n","\n","    Reference:\n","        .. [1] Ioffe, Sergey, and Christian Szegedy. \"Batch normalization: Accelerating deep network training by reducing internal covariate shift.\" *ICML 2015*\n","        .. [2] Hang Zhang, Kristin Dana, Jianping Shi, Zhongyue Zhang, Xiaogang Wang, Ambrish Tyagi, and Amit Agrawal. \"Context Encoding for Semantic Segmentation.\" *CVPR 2018*\n","\n","    Examples:\n","        >>> m = DistSyncBatchNorm(100)\n","        >>> net = torch.nn.parallel.DistributedDataParallel(m)\n","        >>> output = net(input)\n","    \"\"\"\n","    def __init__(self, num_features, eps=1e-5, momentum=0.1, process_group=None):\n","        super(DistSyncBatchNorm, self).__init__(num_features, eps=eps, momentum=momentum, affine=True, track_running_stats=True)\n","        self.process_group = process_group\n","\n","    def forward(self, x):\n","        need_sync = self.training or not self.track_running_stats\n","        process_group = None\n","        if need_sync:\n","            process_group = torch.distributed.group.WORLD\n","            if self.process_group:\n","                process_group = self.process_group\n","            world_size = torch.distributed.get_world_size(process_group)\n","            need_sync = world_size > 1\n","\n","        # Resize the input to (B, C, -1).\n","        input_shape = x.size()\n","        x = x.view(input_shape[0], self.num_features, -1)\n","        #def forward(ctx, x, gamma, beta, running_mean, running_var, eps, momentum, training, process_group):\n","        y = dist_syncbatchnorm(x, self.weight, self.bias, self.running_mean, self.running_var,\n","                               self.eps, self.momentum, self.training, process_group)\n","\n","        #_var = _exs - _ex ** 2\n","        #running_mean.mul_((1 - ctx.momentum)).add_(ctx.momentum * _ex)\n","        #running_var.mul_((1 - ctx.momentum)).add_(ctx.momentum * _var)\n","        return y.view(input_shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ktYh4LeFVtC2"},"source":["import encoding\n","model = encoding.models.get_segmentation_model('deeplab', dataset='citys',\n","                                   backbone=\"resnest50\", aux='True',\n","                                   se_loss='False', norm_layer=DistSyncBatchNorm,\n","                                   base_size=520, crop_size=248)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8vZzwtqKPvWW"},"source":["import torch\n","torch.cuda.empty_cache()\n","# Get the model\n","with torch.no_grad():\n","    checkpoint = torch.load('/content/runs/citys/deeplab/resnest50/default/model_best.pth.tar')\n","    model.load_state_dict(checkpoint['state_dict'])\n","    model.eval()\n","    model.cuda()\n","\n","# Prepare the image\n","filename = '/content/zurich_000050_000019_leftImg8bit.png'\n","img = encoding.utils.load_image(filename).cuda().unsqueeze(0)\n","\n","# Make prediction\n","output = model.evaluate(img.cuda())\n","predict = torch.max(output, 1)[1].cpu().numpy() + 1\n","\n","# Get color pallete for visualization\n","mask = encoding.utils.get_mask_pallete(predict, 'citys')\n","mask.save('/content/output70.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OqUT8Yp2uErC"},"source":["%pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_IT9uHjK3lk4"},"source":["%ls"],"execution_count":null,"outputs":[]}]}